<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://nmashalov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nmashalov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-17T09:19:14+00:00</updated><id>https://nmashalov.github.io/feed.xml</id><title type="html">Nikita Mashalov</title><subtitle>The personal site of Nikita Mashalov. </subtitle><entry><title type="html"></title><link href="https://nmashalov.github.io/blog/2024/2024-01-08-three_d_model/" rel="alternate" type="text/html" title=""/><published>2024-01-17T09:19:14+00:00</published><updated>2024-01-17T09:19:14+00:00</updated><id>https://nmashalov.github.io/blog/2024/2024-01-08-three_d_model</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/2024-01-08-three_d_model/"><![CDATA[<d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction"> Introduction </a></div> <div><a href="#the-score-function-score-based-models-and-score-matching">The score function, score-based models, and score matching</a></div> <div><a href="#langevin-dynamics">Langevin dynamics</a></div> <div><a href="#naive-score-based-generative-modeling-and-its-pitfalls">Naive score-based generative modeling and its pitfalls</a></div> <div><a href="#score-based-generative-modeling-with-multiple-noise-perturbations">Score-based generative modeling with multiple noise perturbations</a></div> <div><a href="#score-based-generative-modeling-with-stochastic-differential-equations-sdes">Score-based generative modeling with stochastic differential equations (SDEs)</a> </div> <ul> <li><a href="#perturbing-data-with-an-sde">Perturbing data with an SDE</a></li> <li><a href="#reversing-the-sde-for-sample-generation">Reversing the SDE for sample generation</a></li> <li><a href="#estimating-the-reverse-sde-with-score-based-models-and-score-matching">Estimating the reverse SDE with score-based models and score matching</a></li> <li><a href="#how-to-solve-the-reverse-sde"> How to solve the reverse SDE </a></li> <li><a href="#probability-flow-ode">Probability flow ODE</a></li> <li><a href="#controllable-generation-for-inverse-problem-solving">Controllable generation for inverse problem solving</a></li> </ul> <div><a href="#connection-to-diffusion-models-and-others">Connection to diffusion models and others</a></div> <div><a href="#concluding-remarks">Concluding remarks</a></div> </nav> </d-contents> <p>Here’s my overview of current achievements in 3D</p> <p>Formats can be transformed</p> <h2 id="two-main-approaches">Two main approaches</h2> <table> <thead> <tr> <th>Flavor</th> <th>Distillation from 2d images</th> <th>Work with 3d models</th> </tr> </thead> <tbody> <tr> <td>Data</td> <td>Cheap</td> <td>Expensive</td> </tr> <tr> <td>Speed</td> <td>currently slow</td> <td>fast</td> </tr> <tr> <td>Influential works</td> <td><a href="https://arxiv.org/pdf/2305.16213.pdf">Profilic Dreamer</a></td> <td><a href="https://arxiv.org/abs/2212.08751">PointE</a></td> </tr> </tbody> </table> <h2 id="3d-representation">3d representation</h2> <p>As pictures have several approaches like SVG and PNG 3d models also have different representation.</p> <ul> <li>NERF</li> </ul> <p>Given the camera position $\mathbf{o}$ and direction $\mathbf{d}$, a batch of rays $\mathbf{r}(k) = o + k\mathbf{d}$ is sampled to render a pixel. The MLP takes $r(k)$ as input and predicts the density $τ$ and color $c$.</p> <p>Final rendered color is given by quadrature:</p> \[C_c(r) = \sum^{N_c}_{i=1} \Omega_i(1-\exp(-\tau_i \delta_i))c_i\] <p>$\Omega$ denotes accumalated transmitance</p> \[\Omega_i = \exp(-\sum^{i-1}_{j=1} \tau_j \delta_j)\] <p>$\delta$ - is distance between adjacent samples.</p> <ul> <li>Textured Mesh</li> </ul> <p>Textured mesh [45] represents the geometry of a 3D object with triangle meshes and the texture with color on the mesh surface. Here the 3D parameter θ consists of the parameters to represent the coordinates of triangle meshes and parameters of the texture. The rendering process g(θ, c) given camera pose c is defined by casting rays from pixels and computing the intersections between rays and mesh surfaces to obtain the color of each pixel. The textured mesh allows high-resolution and fast rendering with differentiable rasterization.</p> <p>Current</p> <h2 id="rendering">Rendering</h2> <p>https://pytorch3d.org/</p> <p>Most crucial equation comes. It’s defined through density estimation</p> <h2 id="nerf">NERF</h2> <p>Awesome overview of NERF are presented in <a href="https://theaisummer.com/nerf/">AI SUMMER</a></p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/three_d_dmodels/neural_field.png" alt="NERF.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>NERF</em></td> </tr> </tbody> </table> <h2 id="techniques">Techniques</h2> <ul> <li>Point Cloud</li> <li>Score Distillation Sampling</li> </ul> <p>I list influential</p> <h2 id="influential-works">Influential works</h2> <p>Google Research</p> <ul> <li>DreamFusion https://dreamfusion3d.github.io/</li> </ul> <h2 id="score-distalation-sampling">Score distalation Sampling</h2> <p>https://pals.ttic.edu/p/score-jacobian-chaining</p> <p>is a widely used method to distill 2D image priors from a pretrained diffusion model ϵϕ into differentiable 3D representations. Given a differentiable generator g and a NeRF model parameterized by θ, its rendered image x can be obtained by x = g(θ). Then, SDS calculates the gradients of NeRF parameters θ by:</p> \[\nabla_\Theta \mathcal{L}_{SDS}(\phi,\mathbf{s}) = \mathrm{E}_{t,\epsilon} \left [\omega_t (\epsilon_\phi(x_t;y,t) - \epsilon) \frac{\partial z_t}{\partial x} {\partial}\right]\] <p>$\omega_t$ is a weighting function that depends on the timestep $t$ and $y$ is the text embedding of given prompt.</p> <h2 id="latest-article">Latest article</h2> <p>x. SDS is an optimization method by distilling pretrained diffusion models,</p> <p>As Advice using</p> <h2 id="resourses">Resourses</h2> <p>In article ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation https://arxiv.org/pdf/2305.16213.pdf Wang et al.</p> <p>their impo</p> <p>https://github.com/yuanzhi-zhu/prolific_dreamer2d/tree/main</p> <h2 id="where-go-further">Where go further</h2> <h2 id="references">References</h2> <p>[1] Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation https://pals.ttic.edu/p/score-jacobian-chaining</p> <p>[2] DreamTime: An Improved Optimization Strategy for Text-to-3D Content Creation https://arxiv.org/pdf/2306.12422.pdf</p> <p>[3] v- ShapE https://arxiv.org/abs/2305.02463</p>]]></content><author><name></name></author></entry><entry><title type="html">Stein Variotional Gradient Descent</title><link href="https://nmashalov.github.io/blog/2024/SVGD/" rel="alternate" type="text/html" title="Stein Variotional Gradient Descent"/><published>2024-01-15T00:00:00+00:00</published><updated>2024-01-15T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/SVGD</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/SVGD/"><![CDATA[<p>Stein Variational Gradient Descent uses a vector field $v$ to sample from prior distribution $\pi$ from $\rho$.</p> \[x^i_{k+1} = x_k^i + \varepsilon v(x_k^i)\] <p>For successful approximation $v$ is optimized via rate</p> \[\arg \sup_{\phi \in C}\{-\partial_\varepsilon KL(T_{\#\rho} \parallel \pi)_{\varepsilon=0}\}\] <p>Note that hedge $#$ hear means push forward operator from measure $\rho$. It’s just a way to emphasize that method is based on operator $T$</p> <p>However, directly computing the vector field is intractable because it is non-trivial to compute the time-dependent score function ∇θ log µτ (θ). To tackle this issue, traditional ParVI methods either restrict the functional gradient within RKHS and leverage analytical kernels to approximate the vector field or , or learn a neural network to estimate the vector field</p> <h2 id="wasserstein-gradient-flow">Wasserstein Gradient Flow</h2> <p>Large-Scale Wasserstein Gradient Flows https://arxiv.org/pdf/2106.00736.pdf</p> <p>The term on the right can be understood as the gradient of F in Wasserstein space, a vector field perturbatively rearranging the mass in ρt to yield the steepest possible local change of F. Wasserstein gradient flows are used in various applications:</p> \[\frac{\partial \rho_t}{\partial t} = \text{div}(\rho_t \nabla_x \mathbf{F}(\rho_t))\] <p>Continuity equation</p> <p>Fokker-Plank free energy functional</p> \[F_{FP}(\rho)= U(\rho) - \beta^{-1} \mathcal{E}_\rho\] <h2 id="stein-operator">Stein operator</h2> \[S_\pi \phi = \nabla \log \pi \phi + \nabla \dot \phi\] <p>We need to find field $\phi$ that will transform prior distribution to posterior $\pi$</p> <h2 id="probability-metric">Probability metric</h2> <p>https://www.cs.toronto.edu/tss/files/papers/2021-SteinsMethodSurvey-Li.pdf</p> <p>Definition. Probability measures $\mu$ and $\nu$ on familiy $\mathbf{H}$ of test functions</p> \[d_{\mathbf{H}}(\mu, \nu) = \sup_{h \in \mathbf{H}} \left| \int h(x)d\mu(x) - \int g(x) d\nu(x)\right|\] <p>Wasserstein metric</p> <p>Family is defined via 1-Lipshitz functions $W$</p> \[d_W = \sup_{h\in W}|\mathrm{E}h(y)-\mathrm{E}h(Z)|\] <p>Stein identity</p> \[E f'(Z) = EZ f(Z)\] <table> <tbody> <tr> <td>for all absolute continious functions $f: \mathrm{R} \rightarrow \mathrm{R}$ with $\mathrm{E}</td> <td>f’(Z)</td> <td>&lt; \infty$</td> </tr> </tbody> </table> <h2 id="mean-field">Mean-field</h2> \[\frac{d X^i_t}{d t} = - \underbrace{\frac{1}{N} \sum_{j=1}^N \nabla k (X^i_t, X^j_t)}_{repulsion between particles} - \frac{1}{N}\] <h2 id="wasserstein-space">Wasserstein space</h2> <p>Denote $L^2_q$ as Hilbert Space of $\mathrm{R}^D$ valued functions with :</p> <ol> <li>u: $\mathrm{R^D} \rightarrow \mathrm{R^D} $ \(|\int\|u(x)\|^2_2 dq &lt; \infty|\)</li> <li>Inner product \(&lt;u,v&gt;_{L^2_q} = \int u(x) \dot v(x) dq\)</li> </ol> <p>\(\partial_t q_t + \nabla \dot (v_tq_t)=0,\) $v_t \in \bar{{\nabla \phi: \phi \in C_c^\infty}}$</p> <h2 id="gradient-flows">Gradient flows</h2> <p>Langevin and SGVD are gradient flows of KL divergence but with different metrics on $P(\mathbf{R}^d)$</p> <p>Langevin gradient flow approximation</p> \[\rho_{n+1} = \argmin_{\rho}(KL(\rho|\pi) + \frac{1}{\varepsilon} d^2_{OT}(\rho,\rho_n))\] <p>SGVD gradient flow approximation</p> \[\rho_{n+1} = \argmin_{\rho}(KL(\rho|\pi) + \frac{1}{\varepsilon} d^2_{K}(\rho,\rho_n))\] <p>Wasserstein geometry</p> <h2 id="particle-based-variational-inference">Particle-based Variational Inference</h2> <p>Typically, the measure µτ follows the “steepest descending curves” of a functional on W2(Θ),</p> <h2 id="practical-usage-of-svgd">Practical usage of SVGD</h2> <p><a href="https://arxiv.org/pdf/2305.16213.pdf">Profilic dreamer</a> - text-to-3D generation.</p> <p>Similarity between</p> <p>Compared with the vanilla SDS in Eq. (2) which optimizes the parameter θ in the parameter space Θ, here we aim to optimize the distribution (measure) µ(θ|y) in the function space W2(Θ).</p> \[\min_{\mu \in W_2(\Theta)} \varepsilon[\mu] = \mathrm{E}_{t,\varepsilon,c} [\frac{\sigma_t}{\alpha_T} \omega(t) D_{KL}(q_t^\mu(x_t|c,y) \parallel p_t(x_t|y^c))]\] <p>They derive the gradient flow minimizing $\mathcal{E}[\mu]$ in $\mathrm{W}_2(\Theta)$ and so update rule</p> \[\frac{\partial \mu_\tau(\theta|y)}{\partial \tau} = - \nabla_\theta \left[\mu_\tau(\theta|y) \mathrm{E}_{t,\epsilon,c}[\sigma_t \omega(t)(\nabla_{\mathbf{x}_t} \log p_t(\mathbf{x}_t|y^c)- \nabla_{x_t} \log q_t^{\mu_t}(\mathbf{x}_t|c,y) \frac{\mathbf{g}(\theta,c)}{\partial \theta})] \right]\] <p>update rule</p> \[\frac{d \theta_\tau}{d \tau} = \mathrm{E}_{t,\epsilon,c}[\sigma_t \omega(t)(\nabla_{\mathbf{x}_t} \log p_t(\mathbf{x}_t|y^c)- \nabla_{x_t} \log q_t^{\mu_t}(\mathbf{x}_t|c,y) \frac{\mathbf{g}(\theta,c)}{\partial \theta})]\] <p>Theorem 3 shows that by letting the random variable θτ ∼ µτ (θτ |y) move across the ODE trajectory in Eq. (12), its underlying distribution µτ will move by the direction of the steepest descent that minimizes E[µ].</p> <p>Therefore, to obtain samples (in Θ) from µ ∗ = arg minµ E[µ], we can simulate the ODE in Eq. (12) by estimating two score functions ∇xt log pt(xt|y c ) and ∇xt log q µτ t (xt|c, y) at each ODE time τ , which corresponds to the VSD objective in Eq. (9).</p> <p>Proof. Hope it will help you acquire habbit:</p> <p>Gradient flow minimizing $\mathcal{E}[\mu]$ on $\mathrm{W}_2(\Theta)$ satisfies:</p> \[\frac{\partial\mu_\tau}{\partial \tau} = - \nabla_{\mathrm{W}_2} \mathcal{E}[\mu] = \nabla_\theta (\mu_t \nabla_\theta \frac{\delta \mathcal{E}[\mu_t]}{\delta \mu_t})\] <p>Calculating derivative</p> \[(\frac{\delta D_{KL}(q \parallel p)}{\delta q})[x] = \log q(x) - \log p(x) + 1\] \[\frac{\delta q_t^\mu(\mathbf{x}_t|c,y)}{\delta \mu}[\theta] = q_{t0}(\mathbf{x_t}|\mathbf{x_0}) = \mathcal{N}(\mathbf{x}_t| \alpha_tx_0)\] <p>By definition of $q_t^\mu$</p> \[q_t^\mu(\mathbf{x_t}|c,y) = \mathrm{E}_{q_0^\mu(\mathbf{x}_0|c,y)}[q_{t0}(\mathbf{x}_t|\mathbf{x}_0)] = \mathrm{\mu(\theta|y)}[q_{t0}(\mathbf{x_t}|\mathbf{g}(\theta,c))]\] <p>Fokker-Plank equation helps to connect measure equation with particle.</p> <p>References</p> <ol> <li>Andrew Duncan – On the Geometry of Stein Variational Gradient Descent https://www.youtube.com/watch?v=1Ec7Eoa5W7g</li> <li>Understanding and Accelerating Particle-Based Variational Inference https://arxiv.org/pdf/1807.01750.pdf</li> <li>B. T. Polyak, Some methods of speeding up the convergence of iteration methods https://www.mathnet.ru/links/e4418385804fdfbc633dced14b9713ec/zvmmf7713.pdf</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[Stein Variational Gradient Descent uses a vector field $v$ to sample from prior distribution $\pi$ from $\rho$.]]></summary></entry><entry><title type="html">Stein Variotional Gradient Descent</title><link href="https://nmashalov.github.io/blog/2024/fisher/" rel="alternate" type="text/html" title="Stein Variotional Gradient Descent"/><published>2024-01-15T00:00:00+00:00</published><updated>2024-01-15T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/fisher</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/fisher/"><![CDATA[<p>https://www.youtube.com/watch?v=elSmfwHNTRc</p> <p>Fisher information metric</p> \[\text{KL}(f_\theta|f_{\theta+d\theta}) = \frac{1}{2} (d\theta)^TI(\theta)d\theta +O(|d\theta|^3)\] <p>Fisher information</p> \[I(\theta) = \mathbb{E}_\theta[s_\theta(X)s_\theta(X)^T], s_\theta = \nabla_\theta \log f_\theta(X)\] <p>Fisher information is symmetric positive semi-definite. Defines Riemannian metric on the parameter space(RAO, 1945) - Fisher information metric:</p> \[&lt;d\theta_1, d\theta_2&gt;_\theta = d\theta_1^T I(\theta6) d\theta_2\] <p>So for tangent vector $u,v \in T_\theta \Theta \approx \mathbb{R}^d$</p> \[&lt;u,v&gt;_\theta = u^T I(\theta)\] <h2 id="riemanian-tools">Riemanian tools</h2> <h3 id="angles-and-norms-of-tangent-vectors">Angles and norms of tangent vectors</h3> \[&lt;u,v&gt;_\theta\] <h3 id="lengths">Lengths</h3> \[l(\gamma) = \int_0^1 \|\dot{\gamma}(t)\|_{\gamma(t)}dt\] <h3 id="distances">Distances</h3> \[\text{dist}(\theta_0,\theta_1) = \inf_{\gamma(0)=\theta_0, \gamma(1)=\theta_1} l(\gamma)\] <h3 id="geodesics">Geodesics</h3> <p>Optimal interpolation with zero acceleration</p> \[t \rightarrow \gamma(t), \nabla_{\dot{\gamma}} \dot{\gamma} =0\] <p>$\nabla$ Levi-Civitia connections -&gt; intrisic derivatives of vector fields</p> <h2 id="hopf-rinov-theorem">Hopf-Rinov theorem</h2> <p>If manifold is complete, than any two points can be linked with minimizing geodesics</p> <h2 id="exp-map-and-log-map">Exp map and log map</h2> \[\forall \nu \in T_{\theta_0} \Theta, \exp_{\theta_)}(\nu)=\gamma(1), \text{where } \gamma \text{ is geodesic } \gamma(0)=\theta_0, \dot{\gamma}(0)=\nu\] \[\forall \theta_1 \in \Theta \log_{\theta_0} (\theta_1) = \nu, \text{ where} \exp_{\theta_0}(\nu)=\theta_1\] <h2 id="dual-tools">Dual tools</h2> <ul> <li>Eucledian scalar product $\rightarrow$ Riemannian metric</li> <li>straight lines $\rightarrow$ geodesics</li> <li>Euclidian distance $\rightarrow$ geodesic distance</li> <li>addition/ substraction $\rightarrow$ Riemannian exponential/logarithm</li> </ul> \[x + \nu \rightarrow \exp_x(\nu) \\ x - y \rightarrow \log_x(y)\] <h2 id="frechet-mean">Frechet mean</h2> <p>$x_1,\dots, x_n \in M$ metric space:</p> \[\tilde{x} =\argmin_{x\in M} \frac{1}{n} \sum_{i=1}^n d(x,x_i)^2\]]]></content><author><name></name></author><summary type="html"><![CDATA[https://www.youtube.com/watch?v=elSmfwHNTRc]]></summary></entry><entry><title type="html">Airflow automatization</title><link href="https://nmashalov.github.io/blog/2024/airflow_automation/" rel="alternate" type="text/html" title="Airflow automatization"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/airflow_automation</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/airflow_automation/"><![CDATA[<p>Through my previous year I had intensive work as MLOps specialist. One of my task was to facilitate in-house Airflow provision. I’ll share some techniques, that I developed during my work.</p> <p>Provider haven’t brought any practices of Airflow, so</p> <h2 id="setup">Setup</h2> <p>Result was delivered by cli command to provider server. Serious</p> <p>Simple mistakes could ruin whole production process, so it was nessary to bring several environments.</p> <h2 id="one-operator---many-models">One operator - many models</h2> <p>Provisioner his own operator which was similar to Kubernetes.</p> <h2 id="ci-delivery">CI delivery</h2> <h2 id="environments">Environments</h2> <p>Through my journey I made serious mistake of confusing environments and Git branches.</p> <h2 id="templating-helps">Templating helps</h2> <p>Dag were created</p> <p>Through use of Jinja</p> <p>I provide you with my template to start</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>


</code></pre></div></div> <h2 id="node-based-programming">Node-based programming</h2> <p>Finally</p> <p>I share my</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Through my previous year I had intensive work as MLOps specialist. One of my task was to facilitate in-house Airflow provision. I’ll share some techniques, that I developed during my work.]]></summary></entry><entry><title type="html">Airflow automatization</title><link href="https://nmashalov.github.io/blog/2024/flink-SQL/" rel="alternate" type="text/html" title="Airflow automatization"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/flink-SQL</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/flink-SQL/"><![CDATA[<p>Apache Flink is powerful streaming</p> <p>They have awesome documentation</p> <p>Yet some reasonable features requires ad-hoc. I’ll share you with some of my favorite.</p> <h2 id="understanding-time-in-flink">Understanding time in Flink</h2> <ul> <li>processed time</li> <li>event time</li> </ul> <h3 id="processed-time">Processed time</h3> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    <span class="n">proc_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">()</span>
</code></pre></div></div> <h3 id="event-time">Event time</h3> <p>As kafka is queue events are read sequentially. If we use event time we require</p> <p>When events doesn’t follow shedule they are called</p> <p>For mitigating late events you can use watermark</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">event_ts</span> <span class="nb">timestamp</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
<span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">events_ts</span> <span class="k">AS</span> <span class="n">event_ts</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1'</span> <span class="k">MINUTE</span>
</code></pre></div></div> <p>With such definition we’ll wait for late events for one minute.</p> <p>In brief watermark say operators that events before mark were already processed.</p> <h3 id="example">Example</h3> <p>Suppose we send our dataset of three events happend every minute</p> <table> <thead> <tr> <th>id</th> <th>ts</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>2023-01-12 10:30:00.000</td> </tr> <tr> <td>1</td> <td>2023-01-12 10:31:00.000</td> </tr> <tr> <td>1</td> <td>2023-01-12 10:32:00.000</td> </tr> </tbody> </table> <p>Using proctime</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="k">source</span><span class="p">(</span>
    <span class="n">id</span><span class="p">,</span>
    <span class="n">ts</span><span class="p">,</span>
    <span class="n">proc_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">()</span>
<span class="p">)</span>
<span class="k">FROM</span> <span class="n">source_table</span><span class="p">;</span>

<span class="k">SELECT</span> <span class="n">id</span> 
<span class="k">FROM</span> <span class="k">TABLE</span><span class="p">(</span><span class="n">TUMBLE</span><span class="p">(</span><span class="k">TABLE</span> <span class="k">source</span><span class="p">,</span> <span class="k">DESCRIPTOR</span><span class="p">(</span><span class="n">pc</span><span class="p">),</span> <span class="n">interval</span> <span class="s1">'1'</span> <span class="k">minute</span><span class="p">));</span>
</code></pre></div></div> <p>If we’ll process it through using <code class="language-plaintext highlighter-rouge">processed_time</code> we’ll get 3. Yet with use of</p> <h2 id="field-unpacking">Field unpacking</h2> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div> <h2 id="work-with-array">Work with array</h2> <h2 id="difficult-calculations">Difficult calculations.</h2> <p>Calculations are better perfomed sequentialy</p> <p>Haversine formula is used for calculating distance between two points defined by latitude and longitude.</p> <p>This formula is especially in geo-streaming applications.</p> <p>Exact formula is given by:</p> \[2 r \arcsin\left(\sqrt{\sin^2(\frac{\phi_1-\phi_2}{2}) + \cos \phi_1 \cos \phi_2 \sin^2 (\frac{\lambda_2-\lambda_1}{2})}\right)\] <p>It’s really difficult to</p> <p>I advise you to use chaining for facilitation of your work.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">power</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">locationLng1</span><span class="o">-</span><span class="n">locationLng2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span><span class="mi">360</span><span class="p">.,</span><span class="mi">2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">dlng</span><span class="p">,</span>
<span class="n">power</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">locationLat1</span><span class="o">-</span><span class="n">locationLat2</span><span class="p">)</span><span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span><span class="mi">360</span><span class="p">.,</span><span class="mi">2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">dlat</span><span class="p">,</span>
<span class="n">cos</span><span class="p">(</span><span class="n">locationLat1</span> <span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span> <span class="mi">180</span><span class="p">.)</span> <span class="k">AS</span> <span class="n">cos_loc1</span><span class="p">,</span>
<span class="n">cos</span><span class="p">(</span><span class="n">locationLat2</span> <span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span> <span class="mi">180</span><span class="p">.)</span> <span class="k">AS</span> <span class="n">cos_loc2</span><span class="p">,</span>
</code></pre></div></div> <p>I multiply by <code class="language-plaintext highlighter-rouge">3.14/180.</code> to convert gradus for radians. Earth radius 🌎 is approximately 6371 km. So final distance will be</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">2</span><span class="o">*</span><span class="mi">6371</span><span class="o">*</span><span class="n">asin</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dlat</span><span class="o">+</span><span class="n">cos_loc1</span><span class="o">*</span><span class="n">cos_loc2</span><span class="o">*</span><span class="n">dlng</span><span class="p">))</span>
</code></pre></div></div> <h2 id="use-of-cassandra">Use of Cassandra</h2> <p>Flink provides</p> <p>Not all tables can b</p> <p><a href="https://cassandra.apache.org/_/index.html"></a></p> <h2 id="deduplication">Deduplication</h2> <p>Deduplication is essential in cases when you have a lot of events but you don’t want to overload.</p> <p>First I’ll provide my approach and</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">id</span><span class="p">,</span>
    <span class="n">FIRST_VALUE</span><span class="p">(</span><span class="n">os</span><span class="p">)</span> <span class="k">AS</span> <span class="n">os</span>  
<span class="k">FROM</span> <span class="k">TABLE</span><span class="p">(</span>
    <span class="n">TUBMLE</span><span class="p">(</span>
        <span class="k">TABLE</span> <span class="n">mob_events</span><span class="p">,</span>
        <span class="k">DESCRIPTOR</span><span class="p">(</span><span class="n">proc_time</span><span class="p">),</span>
        <span class="n">INTERVAL</span> <span class="s1">'20'</span> <span class="k">SECOND</span>
    <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="mi">1</span>
</code></pre></div></div> <p>Alternative</p> <p>SELECT id, FIRST_VALUE(os) AS os<br/> FROM TABLE( TUBMLE( TABLE mob_events, DESCRIPTOR(proc_time), INTERVAL ‘20’ SECOND ) ) ) GROUP BY 1</p> <p>This script</p> <p>First of all you need to know about time in Flink There are three types:</p> <ul> <li><strong>Processing time</strong>:</li> <li><strong>Event time</strong>”:</li> <li><strong>Ingestion time</strong>: time when event was <em>ingested</em> to operator</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="p">(</span>
    <span class="p">...</span>
    <span class="n">proc_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">(),</span> 
    <span class="n">row_time</span> <span class="k">AS</span> <span class="k">LOCALTIMESTAMP</span> <span class="c1">-- normal timestamp(3)</span>
<span class="p">)</span> 
</code></pre></div></div> <p>That</p> <p>Also you need to know more about time windows in <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/operators/windows/">Flink</a></p> <h2 id="time-transformation">Time transformation</h2> <p>There a lot of formats of representing of time</p> <ul> <li>UNIX: in milliseconds or seconds from</li> <li>TIMESTAMP:</li> </ul> <p>Flink also specefies difference between timestamp.</p> <ul> <li>TIMESTAMP</li> <li>TIMESTAMP(3) - seconds</li> <li>TIMESTAMP(6) - miliseconds Probable cavets also can be timezones.</li> </ul> <p>For some cases it’s beneficial to convert them to each other</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_source</span><span class="p">(</span>
    <span class="c1">-- first you declare field</span>
    <span class="n">eventUnixTime</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="c1">-- then you transform it</span>
    <span class="c1">-- UNIXTIME work with seconds not ms</span>
    <span class="n">eventTimeStamp</span> <span class="k">AS</span> <span class="n">TO_TIMESTAMP</span><span class="p">(</span><span class="n">FROM_UNIXTIME</span><span class="p">(</span><span class="n">eventTimestamp</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">))</span>
<span class="p">)</span>
</code></pre></div></div> <p>You can cast time like <code class="language-plaintext highlighter-rouge">03-00-00</code> to <code class="language-plaintext highlighter-rouge">TIME</code> via simple:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- now it's TIME format</span>
<span class="k">CAST</span><span class="p">(</span><span class="n">time_zone_tm</span> <span class="k">AS</span> <span class="nb">TIME</span><span class="p">)</span> <span class="k">AS</span> <span class="n">time_zone_tm</span>
</code></pre></div></div> <p>Let’s some up with working case of selecting events from 9 to 20 o’clock with correction of timezone <code class="language-plaintext highlighter-rouge">time_zone_tm</code></p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- I'll write in where </span>
<span class="k">WHERE</span> <span class="n">TIMESTAMPDIFF</span><span class="p">(</span><span class="k">MINUTE</span><span class="p">)</span>
</code></pre></div></div> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- counts minutes from 0:00:00 to current time  </span>
<span class="n">TIMESTAMPDIFF</span><span class="p">(</span><span class="k">MINUTE</span><span class="p">,</span> <span class="k">CAST</span><span class="p">(</span><span class="k">CURRENT_DATE</span> <span class="k">as</span> <span class="n">timestmap</span><span class="p">),</span> <span class="n">LocalTimestmap</span> <span class="p">)</span>
</code></pre></div></div> <p>EXTRACT(HOUR FROM time_zone_tm) * 60 + 7 * 60 + 30 EXTRACT(MINUTE FROM time_zone_tm) + 19 * 60 +15</p> <h2 id="escaping-fields">Escaping fields</h2> <p>FlinkSQL allows to escape field with backticks like that</p> <pre><code class="language-SQL">CREATE TABLE kafka_source {
    id STRING,
    -- event STRING, can throw a mistake :( 
    `event` STRING 
}
</code></pre> <p>It can be a leverage in situation with overloaded words like <code class="language-plaintext highlighter-rouge">group</code> or <code class="language-plaintext highlighter-rouge">event</code></p> <h2 id="json-unpacking">JSON unpacking</h2> <p>Sometimes data in json is provided in encrypted format.</p> <pre><code class="language-JSON">{
    "time_info": 170123456,
    "Data": "asesdasd"
}
</code></pre> <p>First of all you nee</p> <p>Just use</p> <p>JSON_VALUE</p> <p>Flink has documentation, yet it’s syntaxis can look unfamiliar. Actually it’s just a way to navigate through hierarchical structures.</p> <p>I’ll guide you through.</p> <ul> <li><code class="language-plaintext highlighter-rouge">$</code> - mean <code class="language-plaintext highlighter-rouge">self</code> in Python ot <code class="language-plaintext highlighter-rouge">this</code> in JavaScript sense. It</li> <li>[<code class="language-plaintext highlighter-rouge">a</code>] - helps to select field in map</li> <li>[0] - helps to select element in list. Recall that list is ordered structure.</li> </ul> <p>Unfortunatelly you can’t cast extracted field to your desire type inline like that</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>JSON_VALUE('DataJson')

</code></pre></div></div> <p>Sometimes</p> <p>Suppose our message has</p> <p>Yet a lot of</p> <h2 id="join-types">Join types</h2> <p>Joins can mess order of events!</p> <ul> <li> <p>regular join Can bring OOM errors</p> </li> <li> <p>interval join Flink automatically removes events</p> </li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT id

FROM source1 AS t1
JOIN source2 AS t2 ON
    s1.id = s2.id AND
    s1.ts BETWEEN t2.ts - INTERVAL '5' minute AND 
        t2.ts + INTERVAL '5' minute
</code></pre></div></div> <ul> <li>temporal joins Allows to work with time versioned</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT  
FROM events AS t1
LEFT JOIN temporal_table FOR SYSTEM_TIME AS OF t1.event_time AS t2 ON
    t1.id = t2.id
</code></pre></div></div> <p>That join automatically choses maximum time before event.</p> <ul> <li>temporal join</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Apache Flink is powerful streaming]]></summary></entry><entry><title type="html">Airflow automatization</title><link href="https://nmashalov.github.io/blog/2024/optimal_transport/" rel="alternate" type="text/html" title="Airflow automatization"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/optimal_transport</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/optimal_transport/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Optimal transport is useful beyond classical problems of logistic and resource management. That method is somehow universal. I describe from my personal experience in NLP.</p> <p>Optimal transport is useful tool for data scientist. I’ll bring case from my personal practice to prove.</p> <h2 id="bussiness-case-matching-scripts">Bussiness case. Matching scripts</h2> <p>Suppose we have call-center, where junior operators read scripts and more proficient colleagues speak freestyle. We want to match phrases from scripts to new original variations of freestylers.</p> <p>Modern neural nets models BERT provides us with convenient of vector representation of sentences.</p> <p>We actually have two distibutions of sentences. First is for scipt sentences, second for</p> <p>You can read more about embeddings <a href="https://www.turing.com/kb/guide-on-word-embeddings-in-nlp">here</a>.</p> <p>In normal practise we use cosine similarity</p> \[\text{similarity} = \cos(\text{emb}_1,\text{emb}_2)\] <p>All we need is to bring optimal connection.</p> <h2 id="about-optimality">About optimality</h2> <p>Optimality is actually one of the way of thinking and defining objects.</p> <p>What’s more importantly you can relax</p> <h2 id="entropy-regularized-optimal-transport">Entropy regularized optimal transport</h2> \[\int_{x \in \Pi(\mu,\nu)}\] <h2 id="resources">Resources</h2> <p>Computational Optimal Transport by Marco Cuturi https://arxiv.org/pdf/1803.00567.pdf</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Better organization PERT</title><link href="https://nmashalov.github.io/blog/2024/sheduling/" rel="alternate" type="text/html" title="Better organization PERT"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/sheduling</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/sheduling/"><![CDATA[<p>During my interview I was asked about . That was really complex task. I had intuition that it’s well known problem.</p> <h2 id="pert">PERT</h2> <p>https://en.wikipedia.org/wiki/Program_evaluation_and_review_technique</p>]]></content><author><name></name></author><summary type="html"><![CDATA[During my interview I was asked about . That was really complex task. I had intuition that it’s well known problem.]]></summary></entry><entry><title type="html">Streaming architecture</title><link href="https://nmashalov.github.io/blog/2024/streaming-architecture/" rel="alternate" type="text/html" title="Streaming architecture"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/streaming-architecture</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/streaming-architecture/"><![CDATA[<p>Streaming application also known as near real time (NRT) are . They are widely used in credit scoring, geoanalytics and mobile.</p> <p>Current popular solutions are</p> <p>In this article I share my heuristics for building streaming application. I’ll touch upon:</p> <ul> <li>ways to aggregate</li> </ul> <p>Assumptions:</p> <ul> <li>we are provided with enough of kafka</li> </ul> <p>Such assumptions helps us to:</p> <p>We get triggers of all cats</p> <h2 id="onion-architecture">Onion architecture</h2> <p>I’ll give a quick overview over architecture</p> <table> <thead> <tr> <th>Layer</th> <th>Credo</th> <th>Principles</th> <th>Tech realisation</th> </tr> </thead> <tbody> <tr> <td>Feature extraction layer</td> <td>Extract as much as possible</td> <td> </td> <td> </td> </tr> </tbody> </table> <p>Teach realisation:</p> <ul> <li>feature extraction <ul> <li>every side streaming source will have it own kafka topic</li> <li>that topic should be filter only by your domain</li> <li>yet we don’t enrich it yet with our domain info</li> </ul> </li> <li>feature level <ul> <li>we merge all semantics group in one</li> <li>model scheme should have one datamodel</li> </ul> </li> <li>enrichment layer <ul> <li>we enrich</li> </ul> </li> <li>strategy layer <ul> <li>only nessary info for side developer</li> <li>all strategies are merged to one output topic</li> </ul> </li> </ul> <h2 id="architecture-judgement">Architecture judgement</h2> <p>Arhitecture brings useful decomposition</p> <h2 id="feature-level">Feature level</h2> <p>On feature level we are interested on aggregating in planar format.</p> <p>Suppose we have nested structure</p> <h2 id="aggregation-level">Aggregation level</h2> <p>There are two ways to aggregate info with common schema or without. I’ll share pros and cons of both approach.</p> <p>Common schema is beneficial for side developer. As he can. Also common schema allows to use AVRO for effective.</p> <p>Yet standardization can bring serious obstacles:</p> <ul> <li>fields with common</li> </ul> <p>First</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Streaming application also known as near real time (NRT) are . They are widely used in credit scoring, geoanalytics and mobile.]]></summary></entry><entry><title type="html">Neural Painting</title><link href="https://nmashalov.github.io/blog/2024/neural_painting/" rel="alternate" type="text/html" title="Neural Painting"/><published>2024-01-09T00:00:00+00:00</published><updated>2024-01-09T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/neural_painting</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/neural_painting/"><![CDATA[<p>Types:</p> <ul> <li>inpainting</li> <li>stroke-based</li> </ul> <h2 id="style2paints">Style2Paints</h2> <p>Popular tool for colorisation of line art https://lllyasviel.github.io/Style2PaintsResearch/</p> <p>Despite v4 version used classical methods, v5 now use stable diffusion for colorization.</p> <h2 id="tracking">Tracking</h2> <p>https://ttwong12.github.io/papers/toontrack/toontrack.html</p> <h2 id="sceletionization">Sceletionization</h2> <p>https://lllyasviel.github.io/DanbooRegion/paper/paper.pdf</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tricks</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">skimage.morphology</span> <span class="kn">import</span> <span class="n">skeletonize</span><span class="p">,</span> <span class="n">dilation</span>

<span class="k">def</span> <span class="nf">get_skeleton</span><span class="p">(</span><span class="n">region_map</span><span class="p">):</span>
    <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">region_map</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="sh">'</span><span class="s">symmetric</span><span class="sh">'</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Yp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">region_map</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="sh">'</span><span class="s">symmetric</span><span class="sh">'</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">Xp</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">Xp</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">Yp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">Yp</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="n">edge</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">region_map</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">edge</span><span class="p">[</span><span class="n">X</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[</span><span class="n">Y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">skeleton</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="nf">dilation</span><span class="p">(</span><span class="n">edge</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">)</span>
    <span class="n">skeleton</span> <span class="o">=</span> <span class="nf">skeletonize</span><span class="p">(</span><span class="n">skeleton</span><span class="p">)</span>
    <span class="n">skeleton</span> <span class="o">=</span> <span class="p">(</span><span class="n">skeleton</span> <span class="o">*</span> <span class="mf">255.0</span><span class="p">).</span><span class="nf">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="n">field</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">edge</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="nf">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="n">field</span><span class="p">[</span><span class="n">skeleton</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">field</span><span class="p">[</span><span class="n">edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">filter</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">5.0</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">field</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">512</span><span class="p">):</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">filter2D</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CV_32F</span><span class="p">,</span> <span class="nb">filter</span><span class="p">)</span>
        <span class="n">height</span><span class="p">[</span><span class="n">skeleton</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">255.0</span>
        <span class="n">height</span><span class="p">[</span><span class="n">edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">height</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span><span class="o">==</span><span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="kn">import</span> <span class="n">sys</span>
    <span class="n">region_map</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">vis</span><span class="sh">'</span><span class="p">,</span> <span class="nf">get_skeleton</span><span class="p">(</span><span class="n">region_map</span><span class="p">))</span>
    <span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h2 id="datasets">Datasets</h2> <p>Main source of dataset is Danbooru provided by <a href="https://gwern.net/">Gwern</a>.,</p> <p>Dataset preparation:</p> <p>https://github.com/lllyasviel/DanbooRegion/tree/master?tab=readme-ov-file</p> <p>https://gwern.net/doc/ai/anime/danbooru/2023-kim.pdf https://lllyasviel.github.io/SplitFilling/</p> <h2 id="edgar-simo-serra">Edgar Simo-Serra</h2> <p>Collections of work on morphological coloring of pictures. https://esslab.jp/</p> <p>Start from scetch infilling</p> <ul> <li>Scetch Simplification</li> <li>Mastering Sketching https://arxiv.org/pdf/1703.08966.pdf</li> </ul> <p>Dataset</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/drawing/Simo-Serra/drawing.png" alt="drawing.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Sketch Simplification</em></td> </tr> </tbody> </table> <h2 id="notable-work">Notable work</h2> <p>https://github.com/moellenh/flatgan https://dl.acm.org/doi/10.1145/3581783.3613788</p> <p>https://github.com/houseofsecrets/SdPaint Skeletonize</p> <p>https://github.com/ermongroup/SDEdit</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Types: inpainting stroke-based]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://nmashalov.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://nmashalov.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://nmashalov.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>