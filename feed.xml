<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://nmashalov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nmashalov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-24T02:24:12+00:00</updated><id>https://nmashalov.github.io/feed.xml</id><title type="html">Nikita Mashalov</title><subtitle>The personal site of Nikita Mashalov. </subtitle><entry><title type="html">Manifold</title><link href="https://nmashalov.github.io/blog/2024/manifold/" rel="alternate" type="text/html" title="Manifold"/><published>2024-02-23T00:00:00+00:00</published><updated>2024-02-23T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/manifold</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/manifold/"><![CDATA[<p>\</p> <h2 id="intuition">Intuition</h2> <p>Concept of manifold is difficult, due it‚Äôs abstract mathematical deffinition.</p> <p>Blind man and elephant</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/atlas.excalidraw.png" alt="blind_man_elephant.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Rigid body lattice</em></td> </tr> </tbody> </table> <p>As observer it‚Äôs hard to judge the earth is approximatelly a sphere. Yet that conjuction is essential for building</p> <p>So it said, manifold helps to build intuition on surface from it‚Äôs local observation.</p> <h2 id="introduction">Introduction</h2> <p>We‚Äôll start graph, which serves for same goal as manifold in discrete cases. Recall graph is just a collection of edges and</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/graph.excalidraw.png" alt="graph.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Graph is just a bundle of node and edges</em></td> </tr> </tbody> </table> <p>Due to the one of the most important problems, how to find something. Suppose you are foreign city and you want to find supermarket.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/graph.excalidraw.png" alt="graph.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Where I can buy food?</em></td> </tr> </tbody> </table> <p>Let‚Äôs find out it iteratively by visiting nearest streets. For that we use bread-search algorithm.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/graph.gif" alt="graph.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Depth search by <a href="https://slama.dev/manim/camera-and-graphs/">slama.dev</a>. Flash mean observation. Blue node candidates.</em></td> </tr> </tbody> </table> <p>ou walk from your starting point - home and look around. When you‚Äôll observe supermarket. you‚Äô‚Äô build <em>optimal</em> path. In manifold studying it‚Äôs called geodesics.</p> <h2 id="back-to-manifold">Back to manifold</h2> <p>Locally manifold are just normal euclidian. It‚Äôs like graph node stores in it‚Äôs state.</p> <p>Edges are named connection and defined via Cristofel $K$ and Levi-Civitia $\nabla$ symbols.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/graph_holds_plane.excalidraw.png" alt="graph.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Nodes now Euclidian surface, edges Levi-Civitia symbols</em></td> </tr> </tbody> </table> <p>As we understand from discrete representation we need to know to main things, how to measure distance for geodesics. For that we need metric and</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/tangent_space.excalidraw.png" alt="graph.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Tangent space</em></td> </tr> </tbody> </table> <p>Metric is a way of measuring distance between vectors in tangent space. Most common is just an angle.</p> <h2 id="pushworward-pushback-and-pullback-s">Pushworward, pushback and pullback, s</h2> <p>Yet not all manifold are convenient to work about, therefore we can choose a better representation. Something more flat, which allows to better approximate distances and metrics</p> <p>Connection between manifold of studying and better presentation is given map by map $f$.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/representation/net.excalidraw.png" alt="graph.ong"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Tangent space</em></td> </tr> </tbody> </table> <p>We require from this map to be revertible for</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/representation/map.excalidraw.png" alt="map.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Smooth map to more flat space</em></td> </tr> </tbody> </table> <p>For translation vector from tangent space we have pushforward transformations</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/representation/pushforward.excalidraw.png" alt="push_forward.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Pushforward</em></td> </tr> </tbody> </table> <p>Vector can change significantly after pushforawd operation: rotate and scales.</p> <p>Exact transformation is given via pushforward Jacobian in exact point.</p> \[J = \begin{bmatrix} \frac{\partial u_1}{\partial x_1} &amp; \frac{\partial u_1}{\partial x_2} &amp; \frac{\partial u_1}{\partial x_3} \\[1ex] % &lt;-- 1ex more space between rows of matrix \frac{\partial u_2}{\partial x_1} &amp; \frac{\partial u_2}{\partial x_2} &amp; \frac{\partial u_2}{\partial x_3} \\[1ex] \frac{\partial u_3}{\partial x_1} &amp; \frac{\partial u_3}{\partial x_2} &amp; \frac{\partial u_3}{\partial x_3} \end{bmatrix}\] <p>In manifold studying they will bring atlas. Similarity comes fact.</p> <p>Metric works effectively the same, but map is called pullback.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/manifold/representation/pullback.excalidraw.png" alt="push_forward.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Pushforward</em></td> </tr> </tbody> </table> <p>Finally, for metric needed for measuring</p> <h3 id="pushback-properies">Pushback properies</h3> <p>There are some essential properties that we want to preserve</p> <p>When we send structures to like faces we wand them to keep face</p> <p>More formally it‚Äôs named called equivariance</p> <p>|<img src="/assets/img/posts/manifold/equivariance.excalidraw.png" alt="equivariance.png"/> | |:‚Äì:| | *Rotation in both spaces should be seamless. <a href="https://www.youtube.com/watch?v=03MbWVlbefM&amp;t=1393s">Picture link</a> * | Moreover we want to preserve similarity, which comes from angles between vectors. Such transformations are named conformal</p> \[J^T J\] <p>For approxiation of Jacobian we choose sum of eigenvectors with biggest eigenvalues</p> <p>It measures how small changes of one basis affects others. That‚Äôs it. Pairwise interaction between basis vectors.</p> <p>We need to choose vectors that preserve correlations between input features.</p> <p>Recall that eigenvectors are preserved under $$</p> <p>$$</p> <p>So</p> <p>Superficial simmilarity and superposition</p> <p>So than manifold</p> <h2 id="learn-more">Learn more</h2> <p>Visit this fun video <a href="https://www.youtube.com/watch?v=EMJsYBD-dNk">[MATH ONLY] Non-Euclidean Therapy for AI Trauma [Analog Archives]</a> to build manifold intuition with exciting story of diffusion net Alice.</p> <p><a href="https://geomstats.github.io/notebooks/00_foundations__introduction_to_geomstats.html">Geomstats</a>. Python library with rigorous introduction to manifold studying</p> <p>The Lie Derivative for Measuring Learned Equivariance https://arxiv.org/abs/2210.02984</p> <p>Great seminar on geometric learning <a href="https://www.youtube.com/watch?v=03MbWVlbefM&amp;t=1393s">AMMI Seminar - Geometric Deep Learning and Reinforcement Learning (2021)</a></p>]]></content><author><name>Mashalov Nikita</name></author><summary type="html"><![CDATA[Manifold are essential for studying systems that can be observed only locally. Therefore it useful tool for tasks of observation, optimal path finding and generalization of knowledge]]></summary></entry><entry><title type="html">Neuroscience</title><link href="https://nmashalov.github.io/blog/2024/neuroscience/" rel="alternate" type="text/html" title="Neuroscience"/><published>2024-02-21T00:00:00+00:00</published><updated>2024-02-21T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/neuroscience</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/neuroscience/"><![CDATA[<p>Biological networks are much more than just scalar weights. It has activation time and phase different phases of work. Recent works have proved efficacy of neuro-informed approaches.</p> <h2 id="latent-representation">Latent representation</h2> <p>Is a model of perpception. Idea is that we repsent every event as manifold</p> <p>more convenient</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/pitch/pipe.excalidraw.png" alt="pipeline.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">**</td> </tr> </tbody> </table> <p>From perspective of analytic mechanics it means that we coresponds to first integral.</p> <h2 id="ensembles">Ensembles</h2> <p>Combinatorial representation of system as possible collections of states</p> <h2 id="neural-coding">Neural coding</h2> <p>A way how brain transfer information.</p> <h2 id="liquid-networks">Liquid networks</h2> <p>Is‚Äôs a conspect from <a href="https://www.youtube.com/watch?v=IlliqYiRhMU">Liquid Neural Networks</a></p> <p>Leaky-integrator model</p> \[\frac{d \mathbf{x}}{d t} = - \frac{\mathbf{x}(t)}{\tau} + \mathbf{S}(t)\] <p>Conductance-based synapce model</p> \[\mathbf{S}(t) = f(\mathbf{x}(t),\mathbf{I}(t),t, \theta)(A - \mathbf{x}(t))\] \[\frac{d \mathbf{x}}{d t } = - \left[ \frac{1}{\tau} + \underbrace{f(\mathbf{x}(t,\mathbf{I}(t),t,\theta)}_{\text{Liquid variable}}) \right] \mathbf{x}(t) + f(\mathbf{x}(t,\mathbf{I}(t),t,\theta)) A\] <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/neuroscience/liquid_achieve.excalidraw.png" alt="lattice.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Screenshot from presentation</em></td> </tr> </tbody> </table> <h3 id="new-hopfiled-networks">New Hopfiled networks</h3> <p>Recall that are two type of states</p> <p>Were introduced in Paper Dense Associative Memory for Pattern Recognition https://arxiv.org/abs/1606.01164</p> <p>Old pair-wise interaction</p> \[E = - \frac{1}{2} \sum_{i,j=1}^N \sigma_i T_{ij} \sigma_j\] <p>New non-linear</p> \[E = - \sum_{\mu =1}^K F(\xi_i^\mu \sigma_i)\] <p>Which comes in exponential increase in capacity of stored memories.</p> <p>With drawback of that we need to store all of them</p> <p>Increased capacity of recognised</p> <h3 id="reservoir-computing">Reservoir computing</h3> <p>Next generation reservoir computing https://www.nature.com/articles/s41467-021-25801-2</p> <p>Introduction to Next Generation Reservoir Computing https://www.youtube.com/watch?v=wbH4En-k5Gs</p> <h3 id="forward-forward">Forward-forward</h3> <p>Backpropagation and the brain https://www.nature.com/articles/s41583-020-0277-3</p> <p>Checkout notebook</p> <p>https://github.com/EscVM/EscVM_YT/blob/master/Notebooks/2%20-%20PT1.X%20DeepAI-Quickie/pt_1_forward_forward_alg.ipynb</p> <h2 id="read-more">Read more</h2> <p>Lecun Latent World <a href="https://openreview.net/pdf?id=BZ5a1r-kVsf"></a>. Here is effective paraphrase of article. For effective work we need to concentrate, despite changing. For that we have instrisic representation of world. It helps to find something that preserves in time, so we need ti</p> <p>HAMUX https://github.com/bhoov/hamux</p> <p>Free energy Karl Friston https://www.fil.ion.ucl.ac.uk/~karl/A%20free%20energy%20principle%20for%20the%20brain.pdf</p> <p>Relating transformers to models and neural representations of the hippocampal formation https://arxiv.org/abs/2112.04035</p>]]></content><author><name>Mashalov Nikita</name></author><category term="Airflow,"/><category term="s3"/><summary type="html"><![CDATA[Brief overview of advances in conjunction of Deep Learning and neuroscience]]></summary></entry><entry><title type="html">Phase transition in neural nets</title><link href="https://nmashalov.github.io/blog/2024/nn_phase_transition/" rel="alternate" type="text/html" title="Phase transition in neural nets"/><published>2024-02-21T00:00:00+00:00</published><updated>2024-02-21T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/nn_phase_transition</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/nn_phase_transition/"><![CDATA[<h1 id="free-energy">Free energy</h1> <h2 id="energy-based-approach">Energy based approach</h2> <p>Energy based defines probability as</p> \[p(E) = \frac{exp()}{Z}\] <p>$Z$ - partition function .</p> <p>Best papers in field comes from Yann LeCun</p> <p>Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture <a href="https://arxiv.org/abs/2301.08243">paper</a></p> <h2 id="symmetry">Symmetry</h2> <p>–°–∏–º–º–µ—Ç—Ä–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –î–ª—è –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ–≤–æ—Ä–æ—Ç–∞ –≤ nD –Ω—É–∂–Ω–æ n-1 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–∏–Ω–∏–º—É–º. –ï—Å–ª–∏ –∑–∞–¥–∞–≤–∞—Ç—å –≤ –≤–∏–¥–µ –º–∞—Ç—Ä–∏—Ü—ã, —Ç–æ –≤ n —Ä–∞–∑ –±–æ–ª—å—à–µ. –í–Ω—É—Ç—Ä–∏ —Å–µ—Ç–∫–∏ —ç—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—ã—É—á–∏–≤–∞–µ—Ç—Å—è –≤ –≤–∏–¥–µ –∫–∞–∫–æ–π-—Ç–æ —Å–≤–æ–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –µ—â—ë –±–æ–ª—å—à–µ. Therfore for we need more neurons</p> <p>For rotation in nD dimension we at least need n-1 parameters.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/phase_transition/architecture/model.excalidraw.png" alt="high_dim_symmetry.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>No we can‚Äôt handle. We need one more neuron</em></td> </tr> </tbody> </table> <p>Size of neural ensamble</p> <h2 id="analitic-solution-of-attention">Analitic solution of attention</h2> <p>A phase transition between positional and semantic learning in a solvable model of dot-product attention https://arxiv.org/abs/2402.03902</p> <p>Article advices solution of problem and shows phase transition</p> <h2 id="ising-model">Ising model</h2> <h1 id="renormalization">Renormalization</h1> <p>But it might be more intuitive from view of chemistry. Suppose we perfectly know everything about molecule. Every angle and atom of it‚Äôs structure</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/phase_transition/architecture/model.excalidraw.png" alt="chemistry.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>But what will be if we put them all together</em></td> </tr> </tbody> </table> <h2 id="landau-theory-of-phase-transition">Landau theory of phase transition</h2> <p>Main intuition is that radical changes of matter is connected with change of it‚Äôs energetic</p> \[H(X)\] <p>$\Lambda$ is known is order parameter</p> <p>Coherency length</p> \[\xi\] <h2 id="simple-example">Simple example</h2> <p>Brought from awesome video <a href="https://www.youtube.com/watch?v=0OQ7BhlfAJY&amp;t=872s">Renormalization: The Art of Erasing Infinity</a></p> <h2 id="perturbation-theory">Perturbation theory</h2> <h2 id="futher-read">Futher read</h2> <ul> <li>Percolation: a Mathematical Phase Transition https://www.youtube.com/watch?v=a-767WnbaCQ</li> </ul>]]></content><author><name>Mashalov Nikita</name></author><category term="Airflow,"/><category term="s3"/><summary type="html"><![CDATA[Article starts from energy based approaches and comes to phase transition]]></summary></entry><entry><title type="html">Interview</title><link href="https://nmashalov.github.io/blog/2024/interview/" rel="alternate" type="text/html" title="Interview"/><published>2024-01-16T00:00:00+00:00</published><updated>2024-01-16T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/interview</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/interview/"><![CDATA[<p>My interests are generative modeling based on physics and geometrical methods.</p> <p>This is primarily determined by recent advances in generative modeling. Specifically, framework of diffusion networks consisting of closely related markov chains, stochastic ode and langevin dynamics. I believe that solution for coherence of representation of long can be found via analysis through fundamental physics law of continuation and motion.</p> <p>Yandex has rich access to media data. computational resources and experience of developing diffusion networks as YandexART. I am looking for a guidance in writing top papers proposing new approaches.</p> <p>Dream Fusion: Text-to-3D using 2D Diffusion - Preprint https://arxiv.org/abs/2209.14988</p> <p>Artictle proposed a novel approach to text-to-3D synthesis by leveraging a pretrained 2D text-to-image diffusion model. Crucially, the proposed approach eliminates the need for labeled 3D training data and avoids modifications to the image diffusion model. The optimization involves refining a randomly-initialized 3D mode ) through gradient descent, ensuring low loss in its 2D renderings from random angles.</p> <hr/> <p>Profilic dreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation- https://arxiv.org/abs/2305.16213</p> <p>Authors proposed novel approach for distillation 2d diffusion text-to-image models to 3d. They elaborate previous technique SDS introduced in Dream Fusion(https://dreamfusion3d.github.io/) by building distribution of implicit representation rather making it constant. For facilitating computation they utilize particle-based variational inference. I get of method intuition through paper Understanding and Accelerating Particle-Based Variational Inference(https://arxiv.org/pdf/1807.01750.pdf). Despite time consuming inference fidelity approach is much better than competing works. Moreover model enjoy appropriate for diffusion models guidance scale around 10.</p> <p>Action Matching: Learning Stochastic Dynamics from Samples -https://arxiv.org/abs/2210.06662</p> <p>Action Matching addresses the challenge of learning the continuous dynamics of a system when only provided with snapshots of its temporal marginals. I believe that such approaches will help to build semantics of complex actions like.</p> <hr/> <p>I gained great experience by building infrastructures for ML models, which can be easily modified via configs and command line interface. As for code preferences I prefer laconic style and enjoy usage of generator expressions where it possible. When possible I use task specific libraries as it helps concentrate on research task rather.</p> <p>Here‚Äôs representative example of ordering directed graph written in JSON</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># link has format [1,1,0,2,1,'.csv']
# link[0] - id of link (order of bringing links to folder)
# link[1] - id of source node
# link[3] - id of target node
# node.outputs contain use link id
# that's why we need link_map
# you can have better understanding looking at graph.json in test folder
</span>
<span class="c1"># Create a mapping of link IDs to their corresponding links
</span><span class="n">link_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">link</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> <span class="n">link</span> <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">}</span>

<span class="c1"># Define a function to extract relevant IDs from a link
</span><span class="n">extract_ids</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">link_map</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">link_map</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="mi">3</span><span class="p">],)</span>

<span class="c1"># Create a dictionary mapping node links to their corresponding IDs
</span><span class="n">linkage</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nb">input</span><span class="p">.</span><span class="n">link</span><span class="p">:</span> <span class="nf">extract_ids</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">link</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span>
    <span class="k">if</span> <span class="n">node</span><span class="p">.</span><span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">node</span><span class="p">.</span><span class="n">inputs</span>
    <span class="k">if</span> <span class="nb">input</span><span class="p">.</span><span class="n">link</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span>
<span class="p">}</span>

<span class="c1"># Build a directed graph using NetworkX
</span><span class="n">dependency_graph</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">DiGraph</span><span class="p">(</span><span class="n">linkage</span><span class="p">.</span><span class="nf">values</span><span class="p">())</span>

<span class="c1"># Group the generations of the DAG
</span><span class="n">grouped_dag</span> <span class="o">=</span> <span class="p">[</span><span class="nf">sorted</span><span class="p">(</span><span class="n">generation</span><span class="p">)</span> <span class="k">for</span> <span class="n">generation</span> <span class="ow">in</span> <span class="n">nx</span><span class="p">.</span><span class="nf">topological_generations</span><span class="p">(</span><span class="n">dependency_graph</span><span class="p">)]</span>
</code></pre></div></div> <p>Utilization of the ‚ÄúDon‚Äôt Repeat Yourself‚Äù (DRY) principle helped me a lot with learning benefits of abstractions, decomposing and code refactoring. You can see my progress in developing In my project multi-component projects here: https://github.com/NMashalov/PydanticGraph. In PydanticGraph i worked a lot with validation framework Pydantic. That brought me intuition of working with developer abstractions and python inner libraries like importlib.</p> <p>SDEdit: Image synthesis and editing with stochastic differential equations. a</p>]]></content><author><name></name></author><summary type="html"><![CDATA[My interests are generative modeling based on physics and geometrical methods.]]></summary></entry><entry><title type="html">Information geometry</title><link href="https://nmashalov.github.io/blog/2024/information-geometry/" rel="alternate" type="text/html" title="Information geometry"/><published>2024-01-15T00:00:00+00:00</published><updated>2024-01-15T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/information-geometry</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/information-geometry/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Fisher information metric</p> \[\text{KL}(f_\theta|f_{\theta+d\theta}) = \frac{1}{2} (d\theta)^TI(\theta)d\theta +O(|d\theta|^3)\] <p>Fisher information</p> \[I(\theta) = \mathbb{E}_\theta[s_\theta(X)s_\theta(X)^T], s_\theta = \nabla_\theta \log f_\theta(X)\] <h2 id="riemannian-manifold">Riemannian manifold</h2> <p>Fisher information is symmetric positive semi-definite. Defines Riemannian metric on the parameter space(RAO, 1945) - Fisher information metric:</p> \[&lt;d\theta_1, d\theta_2&gt;_\theta = d\theta_1^T I(\theta6) d\theta_2\] <p>So for tangent vector $u,v \in T_\theta \Theta \approx \mathbb{R}^d$</p> \[&lt;u,v&gt;_\theta = u^T I(\theta)\] <h2 id="riemanian-tools">Riemanian tools</h2> <h3 id="angles-and-norms-of-tangent-vectors">Angles and norms of tangent vectors</h3> \[&lt;u,v&gt;_\theta\] <h3 id="lengths">Lengths</h3> \[l(\gamma) = \int_0^1 \|\dot{\gamma}(t)\|_{\gamma(t)}dt\] <h3 id="distances">Distances</h3> \[\text{dist}(\theta_0,\theta_1) = \inf_{\gamma(0)=\theta_0, \gamma(1)=\theta_1} l(\gamma)\] <h3 id="geodesics">Geodesics</h3> <p>Optimal interpolation with zero acceleration</p> \[t \rightarrow \gamma(t), \nabla_{\dot{\gamma}} \dot{\gamma} =0\] <p>$\nabla$ Levi-Civitia connections -&gt; intrisic derivatives of vector fields</p> <h2 id="hopf-rinov-theorem">Hopf-Rinov theorem</h2> <p>If manifold is complete, than any two points can be linked with minimizing geodesics</p> <h2 id="exp-map-and-log-map">Exp map and log map</h2> \[\forall \nu \in T_{\theta_0} \Theta, \exp_{\theta_)}(\nu)=\gamma(1), \text{where } \gamma \text{ is geodesic } \gamma(0)=\theta_0, \dot{\gamma}(0)=\nu\] \[\forall \theta_1 \in \Theta \log_{\theta_0} (\theta_1) = \nu, \text{ where} \exp_{\theta_0}(\nu)=\theta_1\] <h2 id="dual-tools">Dual tools</h2> <ul> <li>Eucledian scalar product $\rightarrow$ Riemannian metric</li> <li>straight lines $\rightarrow$ geodesics</li> <li>Euclidian distance $\rightarrow$ geodesic distance</li> <li>addition/ substraction $\rightarrow$ Riemannian exponential/logarithm</li> </ul> \[x + \nu \rightarrow \exp_x(\nu) \\ x - y \rightarrow \log_x(y)\] <h2 id="freshett-mea">Freshett mea</h2> <p>$x_1,\dots, x_n \in M$ metric space:</p> \[\tilde{x} =\argmin_{x\in M} \frac{1}{n} \sum_{i=1}^n d(x,x_i)^2\] <p>https://www.youtube.com/watch?v=elSmfwHNTRc</p> <hr/> <p>layout: post title: Stein Variational Gradient Descent description: ‚Äî</p> <p>Stein Variational Gradient Descent uses a vector field $v$ to sample from prior distribution $\pi$ from $\rho$.</p> \[x^i_{k+1} = x_k^i + \varepsilon v(x_k^i)\] <p>For successful approximation $v$ is optimized via rate</p> \[\arg \sup_{\phi \in C}\{-\partial_\varepsilon KL(T_{\#\rho} \parallel \pi)_{\varepsilon=0}\}\] <p>Note that hedge $#$ hear means push forward operator from measure $\rho$. It‚Äôs just a way to emphasize that method is based on operator $T$</p> <p>However, directly computing the vector field is intractable because it is non-trivial to compute the time-dependent score function ‚àáŒ∏ log ¬µœÑ (Œ∏). To tackle this issue, traditional ParVI methods either restrict the functional gradient within RKHS and leverage analytical kernels to approximate the vector field or , or learn a neural network to estimate the vector field</p> <h2 id="wasserstein-gradient-flow">Wasserstein Gradient Flow</h2> <p>Large-Scale Wasserstein Gradient Flows https://arxiv.org/pdf/2106.00736.pdf. Is a method based on the Wasserstein gradient flows, that was proposed for solution of the Fokker-Planck equation.</p> <p>The term on the right can be understood as the gradient of F in Wasserstein space, a vector field perturbatively rearranging the mass in œÅt to yield the steepest possible local change of F. Wasserstein gradient flows are used in various applications:</p> \[\frac{\partial \rho_t}{\partial t} = \text{div}(\rho_t \nabla_x \mathbf{F}(\rho_t))\] <p>Continuity equation</p> <p>Fokker-Plank free energy functional</p> \[F_{FP}(\rho)= U(\rho) - \beta^{-1} \mathcal{E}_\rho\] <h2 id="stein-operator">Stein operator</h2> \[S_\pi \phi = \nabla \log \pi \phi + \nabla \dot \phi\] <p>We need to find field $\phi$ that will transform prior distribution to posterior $\pi$</p> <h2 id="probability-metric">Probability metric</h2> <p>https://www.cs.toronto.edu/tss/files/papers/2021-SteinsMethodSurvey-Li.pdf</p> <p>Definition. Probability measures $\mu$ and $\nu$ on familiy $\mathbf{H}$ of test functions</p> \[d_{\mathbf{H}}(\mu, \nu) = \sup_{h \in \mathbf{H}} \left| \int h(x)d\mu(x) - \int g(x) d\nu(x)\right|\] <p>Wasserstein metric</p> <p>Family is defined via 1-Lipshitz functions $W$</p> \[d_W = \sup_{h\in W}|\mathrm{E}h(y)-\mathrm{E}h(Z)|\] <p>Stein identity</p> \[E f'(Z) = EZ f(Z)\] <table> <tbody> <tr> <td>for all absolute continious functions $f: \mathrm{R} \rightarrow \mathrm{R}$ with $\mathrm{E}</td> <td>f‚Äô(Z)</td> <td>&lt; \infty$</td> </tr> </tbody> </table> <h2 id="mean-field">Mean-field</h2> \[\frac{d X^i_t}{d t} = - \underbrace{\frac{1}{N} \sum_{j=1}^N \nabla k (X^i_t, X^j_t)}_{repulsion between particles} - \frac{1}{N}\] <h2 id="wasserstein-space">Wasserstein space</h2> <p>Denote $L^2_q$ as Hilbert Space of $\mathrm{R}^D$ valued functions with :</p> <ol> <li>u: $\mathrm{R^D} \rightarrow \mathrm{R^D}$ \(|\int\|u(x)\|^2_2 dq &lt; \infty|\)</li> <li>Inner product \(&lt;u,v&gt;_{L^2_q} = \int u(x) \dot v(x) dq\)</li> </ol> <p>\(\partial_t q_t + \nabla \dot (v_tq_t)=0,\) $v_t \in \bar{{\nabla \phi: \phi \in C_c^\infty}}$</p> <h2 id="gradient-flows">Gradient flows</h2> <p>Langevin and SGVD are gradient flows of KL divergence but with different metrics on $P(\mathbf{R}^d)$</p> <p>Langevin gradient flow approximation</p> \[\rho_{n+1} = \argmin_{\rho}\left(KL(\rho|\pi) + \frac{1}{\varepsilon} d^2_{OT}(\rho,\rho_n)\right)\] <p>SGVD gradient flow approximation</p> \[\rho_{n+1} = \argmin_{\rho}\left(KL(\rho|\pi) + \frac{1}{\varepsilon} d^2_{K}(\rho,\rho_n)\right)\] <p>Wasserstein geometry</p> <h2 id="particle-based-variational-inference">Particle-based Variational Inference</h2> <p>Typically, the measure ¬µœÑ follows the ‚Äústeepest descending curves‚Äù of a functional on W2(Œò),</p> <h2 id="practical-usage-of-svgd">Practical usage of SVGD</h2> <p><a href="https://arxiv.org/pdf/2305.16213.pdf">Profilic dreamer</a> - text-to-3D generation.</p> <p>Similarity between</p> <p>Compared with the vanilla SDS in Eq. (2) which optimizes the parameter Œ∏ in the parameter space Œò, here we aim to optimize the distribution (measure) ¬µ(Œ∏|y) in the function space W2(Œò).</p> \[\min_{\mu \in W_2(\Theta)} \varepsilon[\mu] = \mathrm{E}_{t,\varepsilon,c} [\frac{\sigma_t}{\alpha_T} \omega(t) D_{KL}(q_t^\mu(x_t|c,y) \parallel p_t(x_t|y^c))]\] <p>They derive the gradient flow minimizing $\mathcal{E}[\mu]$ in $\mathrm{W}_2(\Theta)$ and so update rule</p> \[\frac{\partial \mu_\tau(\theta|y)}{\partial \tau} = - \nabla_\theta \left[\mu_\tau(\theta|y) \mathrm{E}_{t,\epsilon,c}[\sigma_t \omega(t)(\nabla_{\mathbf{x}_t} \log p_t(\mathbf{x}_t|y^c)- \nabla_{x_t} \log q_t^{\mu_t}(\mathbf{x}_t|c,y) \frac{\mathbf{g}(\theta,c)}{\partial \theta})] \right]\] <p>update rule</p> \[\frac{d \theta_\tau}{d \tau} = \mathrm{E}_{t,\epsilon,c}[\sigma_t \omega(t)(\nabla_{\mathbf{x}_t} \log p_t(\mathbf{x}_t|y^c)- \nabla_{x_t} \log q_t^{\mu_t}(\mathbf{x}_t|c,y) \frac{\mathbf{g}(\theta,c)}{\partial \theta})]\] <p>Theorem 3 shows that by letting the random variable Œ∏œÑ ‚àº ¬µœÑ (Œ∏œÑ |y) move across the ODE trajectory in Eq. (12), its underlying distribution ¬µœÑ will move by the direction of the steepest descent that minimizes E[¬µ].</p> <p>Therefore, to obtain samples (in Œò) from ¬µ ‚àó = arg min¬µ E[¬µ], we can simulate the ODE in Eq. (12) by estimating two score functions ‚àáxt log pt(xt|y c ) and ‚àáxt log q ¬µœÑ t (xt|c, y) at each ODE time œÑ , which corresponds to the VSD objective in Eq. (9).</p> <p>Proof. Hope it will help you acquire habbit:</p> <p>Gradient flow minimizing $\mathcal{E}[\mu]$ on $\mathrm{W}_2(\Theta)$ satisfies:</p> \[\frac{\partial\mu_\tau}{\partial \tau} = - \nabla_{\mathrm{W}_2} \mathcal{E}[\mu] = \nabla_\theta (\mu_t \nabla_\theta \frac{\delta \mathcal{E}[\mu_t]}{\delta \mu_t})\] <p>Calculating derivative</p> \[(\frac{\delta D_{KL}(q \parallel p)}{\delta q})[x] = \log q(x) - \log p(x) + 1\] \[\frac{\delta q_t^\mu(\mathbf{x}_t|c,y)}{\delta \mu}[\theta] = q_{t0}(\mathbf{x_t}|\mathbf{x_0}) = \mathcal{N}(\mathbf{x}_t| \alpha_tx_0)\] <p>By definition of $q_t^\mu$</p> \[q_t^\mu(\mathbf{x_t}|c,y) = \mathrm{E}_{q_0^\mu(\mathbf{x}_0|c,y)}[q_{t0}(\mathbf{x}_t|\mathbf{x}_0)] = \mathrm{\mu(\theta|y)}[q_{t0}(\mathbf{x_t}|\mathbf{g}(\theta,c))]\] <p>Fokker-Plank equation helps to connect measure equation with particle.</p> <p>References</p> <ol> <li>Andrew Duncan ‚Äì On the Geometry of Stein Variational Gradient Descent https://www.youtube.com/watch?v=1Ec7Eoa5W7g</li> <li>Understanding and Accelerating Particle-Based Variational Inference https://arxiv.org/pdf/1807.01750.pdf</li> <li>B. T. Polyak, Some methods of speeding up the convergence of iteration methods https://www.mathnet.ru/links/e4418385804fdfbc633dced14b9713ec/zvmmf7713.pdf</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Airflow</title><link href="https://nmashalov.github.io/blog/2024/airflow/" rel="alternate" type="text/html" title="Airflow"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/airflow</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/airflow/"><![CDATA[<d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="##Why care?"> Why care? </a></div> <div><a href="##tools"> Tools </a></div> <div><a href="##team"> Team </a></div> <div><a href="##code implementation">Code implementation</a></div> </nav> </d-contents> <p>Through year I had intensive work with Airflow as MLOps specialist. My primer task was to facilitate in-house Airflow provision. I‚Äôll share ideas and setup, that</p> <p>Blog divided in three parts:</p> <ol> <li>Linkage between tools of versioning Gitlab, storage s3 and Airflow</li> <li>Covers responsibility delegation in team</li> <li>Suggest code for introduced concepts</li> </ol> <p>If you prefer, you can material on <a href="WIP">youtube</a> or look through <a href="https://docs.google.com/presentation/d/1ZDHUNOikAwtRWcU3ctK962KErVaah2iQ4PrRD5tZjr8/edit?usp=sharing">presentation</a></p> <h2 id="why-care">Why care?</h2> <p>Following chapter is pure introduction and inspiration. You can skip it freely, if you want :)</p> <h3 id="pipelines">Pipelines</h3> <p>Pipelining is an art of organization domain specific tools. They skill helps to fasten things a lot, since there are a lot of cool open source tools.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/pitch/pipe.excalidraw.png" alt="pipeline.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Pipelining is an art of organization</em></td> </tr> </tbody> </table> <p>Such pipes are handled by ‚Äòglue‚Äô shell scripting languages like bash</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> traced_images <span class="o">&amp;&amp;</span> <span class="nb">cat </span>img_path.txt | xargs <span class="nt">-I</span> <span class="o">{}</span> potrace <span class="o">{}</span> <span class="nt">-O</span> 
</code></pre></div></div> <p>Parallel with old tools like bash is essential as documentation of orchestration assumes that you have profficience with and recognized it‚Äôs limit. Mainly because such tools doesn‚Äôt go well beyond one machine and sysadmin. Therefore we need better tools</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/pitch/renormalisation.excalidraw.png" alt="groups.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Something more scalable</em></td> </tr> </tbody> </table> <h3 id="orchestration">Orchestration</h3> <p>Orchestration is a way of renormalizing pipelining on level of systems. It contains lot‚Äôs of pipelines and soon after srchestration tool are basically become project heart.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/pitch/essential.excalidraw.png" alt="groups.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Comes</em></td> </tr> </tbody> </table> <p>Therefore orchestrators come with tools of adaption to environment modification and wiring.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/pitch/tools.excalidraw.png" alt="renorm.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Renormalization</em></td> </tr> </tbody> </table> <h2 id="tools">Tools</h2> <p>Section will provide setup explanation and</p> <p>Before we start I‚Äôll share some core concepts about Airflow.</p> <h3 id="airflow-brief-introduction">Airflow. Brief introduction</h3> <p>Apache Airflow is an open-source platform designed to programmatically compose pipeline, schedule them and monitor them in powerful UI. Main language is Python</p> <p>Basic primitive is a Directed Acyclic Graphs (DAGs).</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/tutorial/dag.excalidraw.png" alt="dag.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Intuitive representation of pipeline</em></td> </tr> </tbody> </table> <p>Nodes here represents action to executed, links it‚Äôs order.</p> <p>That abstraction is boosted with scheduling</p> <p>For better perception can be organized in groups.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/tutorial/groups.excalidraw.png" alt="groups.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Semantic organization</em></td> </tr> </tbody> </table> <p>By default operators are executed via <a href="https://docs.celeryq.dev/">Celery</a>, but can also be modified for running on <a href="https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/operators.html">Kubernetes</a>.</p> <p>You can learn more about Airflow from official documentation on <a href="https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html">DAG</a>. If you want to practice, you can also refer to my tutorial on starting with Airflow on toy OCR app <a href="https://github.com/NMashalov/Airflow_tutorial">Github Link</a>.</p> <p>I‚Äôll warn you that from outbox Airflow:</p> <ul> <li>doesn‚Äôt provide any options for .</li> </ul> <h3 id="setup">Setup</h3> <p>In-house solution already done all all DevOps work of the deployment, configuration, and monitoring of Airflow instances. Provider ensured scalability, reliability, and performance.</p> <p>Pipelines are provided to Airflow via cli command, which can be executed both locally and</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/architecture/airflow_delivery.excalidraw.png" alt="s3_airflow.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Our dream team</em></td> </tr> </tbody> </table> <p>Yet it comes with restriction of Airflow environments, manage dependencies, which could be mitigated with building custom airflow docker image.</p> <p>Moreover, it introduced convenient way of job execution defined by yaml. It‚Äôs api is quite transparent, I‚Äôll provide you comments to</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">job</span><span class="pi">:</span>
    <span class="na">resourse_flavor</span><span class="pi">:</span> <span class="s">cpu-16gb</span> <span class="c1"># configures amount of cpu, gpu and ram</span>
    <span class="na">docker_image</span><span class="pi">:</span> <span class="s">python3-11</span> <span class="c1"># sets image </span>
    <span class="na">excecution_time</span><span class="pi">:</span> <span class="s">60 minutes</span> <span class="c1"># time of execution. After job ungracefully shuts</span>
    <span class="na">execution_script</span><span class="pi">:</span> <span class="s">python main.py</span> <span class="c1"># defines script that will be executed through job</span>
</code></pre></div></div> <p>And a way of handling big files from executions through s3</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/architecture/handling_files.excalidraw.png" alt="s3_airflow.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Transportation as a service</em></td> </tr> </tbody> </table> <p>Therefore introduced techniques are primarly oriented for effective utilizations of provided features and effective ML team collaboration.</p> <h3 id="problems-">Problems üö®</h3> <p>Main problem were:</p> <ul> <li>testing models inference and node functionality was extremely on server</li> <li>monitoring of dags execution and data delivery</li> <li>environment setting</li> <li>no reasonable solution for reuse of already prepared dag</li> </ul> <p>I‚Äôll introduce solution for every problem through next paragraphs</p> <h3 id="cli-apps-for-testing">CLI apps for testing</h3> <p>Cli apps facilitate testing as their should behave equally in fast local environment and</p> <p>When app is ready we can have following options</p> <ul> <li>push to Python package storage, from where we‚Äôll pip install it in execution job</li> <li>make a docker image with install cli option</li> </ul> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/architecture/upload.excalidraw.png" alt="s3_airflow.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Our dream team</em></td> </tr> </tbody> </table> <h3 id="model-delivery">Model delivery</h3> <p>Also repo contains reproduction code for model. Reproduction is done with usage</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/architecture/model.excalidraw.png" alt="s3_airflow.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Training is performed in job, that is called in CI script. Than model proceeds to designated model bucket</em></td> </tr> </tbody> </table> <p>Every option is actually great and should be facilitated for usage</p> <h3 id="pipeline-for-repetitive-code">Pipeline for repetitive code</h3> <p>Main observation was that dags are mostly similar and has structure of Extract Transform Load(ETL).</p> <p>Therefore they can be replaced with simple yaml structure. I‚Äôll provide you with prototype</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">dag</span><span class="pi">:</span> <span class="c1"># dag info</span>
    <span class="na">name</span><span class="pi">:</span> 
    <span class="na">schedule</span><span class="pi">:</span> <span class="s2">"</span><span class="nv"> </span><span class="s">"</span> <span class="c1"># simple cron expression</span>
    <span class="na">base_resourse</span><span class="pi">:</span> <span class="s">cpu</span>
    <span class="na">critical</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">tasks</span><span class="pi">:</span>
  <span class="na">read</span><span class="pi">:</span> <span class="c1"># arbitrary group name</span>
    <span class="na">load_csv</span><span class="pi">:</span> <span class="c1"># arbitrary task name</span>
      <span class="na">operator_type</span><span class="pi">:</span> <span class="s">pg_to_csv</span>
      <span class="na">columns</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">ham</span>
        <span class="pi">-</span> <span class="s">bam</span>
<span class="nn">...</span>
</code></pre></div></div> <p>Such solutions allows to abstract from Airflow and can be scaled via interactive UI. Moreover, it is useful for versioning of code and correction on fly from gitlab editor.</p> <p>Overall pipeline looks like:</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/architecture/templates.excalidraw.png" alt="template.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Gitlab templates blank for each yaml pipeline definition</em></td> </tr> </tbody> </table> <p>There are some open-source, that already implemented yaml declarative approach:</p> <ul> <li>dag-factory: <a href="https://github.com/ajbosco/dag-factory">https://github.com/ajbosco/dag-factory</a></li> <li>airflow-declarative: <a href="https://github.com/rambler-digital-solutions/airflow-declarative">https://github.com/rambler-digital-solutions/airflow-declarative</a></li> </ul> <h3 id="environment-variables">Environment variables</h3> <p>Unfortunatelly we don‚Äôt have access to environment variables of Airflow. Therefore we have two options:</p> <ul> <li>set environments from UI, which is not scalable</li> <li>set environment of Airflow can be defined through Airflow variables</li> </ul> <p>Second option is better, yet it requires quite long chain for completion.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/architecture/model.excalidraw.png" alt="s3_airflow.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Training is performed in job, that is called in CI script. Than model proceeds to designated bucket</em></td> </tr> </tbody> </table> <p>Basically configuration yaml look like that:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">postgres_db_connection</span><span class="pi">:</span>
  <span class="na">password</span><span class="pi">:</span> <span class="s">${PG_PASSWORD}</span>
</code></pre></div></div> <p>Bash util <code class="language-plaintext highlighter-rouge">envsubst</code> will fill fields as <code class="language-plaintext highlighter-rouge">${PG_PASSWORD}</code> with respect value from Gitlab CI variables.</p> <p>Before we can start inference we need to deliver our files to production. Our provides can grab files for inference from s3.</p> <p>Repository of airflow and model were separated</p> <h2 id="team">Team</h2> <p>Architecture is seeking for ability for delegating responsibilities</p> <h3 id="responsibility-delegating">Responsibility delegating</h3> <p>Business critical processes requires swift responses for change of production environments . Hence specialists should be able to effectively collaborate in critical situations.</p> <p>Commonly used technique for that is introducing role model for specialists with.</p> <h3 id="airflow-team">Airflow team</h3> <p>Management</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/team.excalidraw.png" alt="team.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Our dream team</em></td> </tr> </tbody> </table> <p>Note that every specialist should be essential, beneficial for and has an ability to master his skills.</p> <h3 id="data-scientist">Data Scientist</h3> <p>Analytic concentrates on novel ideas for models and bring/</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/roles/ds/ds.excalidraw.png" alt="ds.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Provider of novel ideas</em></td> </tr> </tbody> </table> <p>Growth:</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/roles/ds/growth.excalidraw.png" alt="ds_growth.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Stronger algorithm generalization</em></td> </tr> </tbody> </table> <p>Main track of learning is providing more flexible solutions. It includes:</p> <ul> <li>search new ideas, incorporating new solutions</li> <li>creating valence operators, that can handle arbitrary amount and type of data</li> <li>provide best solution for analytic task</li> <li>data quality organization</li> </ul> <h3 id="data-engineer">Data engineer</h3> <p>He knows bases of devops, yet specify his skills in building robust and flexible pipelines. Although role can be modified via</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/roles/engineer/engineer.excalidraw.png" alt="team.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Builds functional operator, scales code</em></td> </tr> </tbody> </table> <p>Engineer is mostly responsible for:</p> <ul> <li>help of analytics with optimal pipeline solution</li> <li>development of new operator for connection</li> <li>bringing</li> </ul> <p>Main track of learning is providing more flexible solutions. It includes:</p> <ul> <li>gluing code with bash</li> <li>creating valent operators, that can handle arbitary amount and type of data</li> <li>provide best solution for analytic task</li> <li>data quality organization</li> </ul> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/roles/engineer/growth.excalidraw.png" alt="team.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Builds functional operator, scales code</em></td> </tr> </tbody> </table> <p>Although he helps to relaxate climax situation. He helps analytic and discuss tests.</p> <h3 id="developer">Developer</h3> <p>Mostly responsible for:</p> <ul> <li>scalability</li> <li>introducing CI building process</li> <li>ease of configuration Therefore role ease building of new dags and their monitoring.</li> </ul> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/roles/developer/developer.excalidraw.png" alt="developer.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Scales and rescales</em></td> </tr> </tbody> </table> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/roles/developer/growth.excalidraw.png" alt="developer.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Developer learns scaling</em></td> </tr> </tbody> </table> <h3 id="cli-as-communication-protocol">CLI as communication protocol</h3> <p>Support for pipeline in working condition is mainly responsibility of engineer therefore he need to make sure, that Data Scientist code is reliable.</p> <p>Cli app coupled with tests is simple, yet effective way to do that:</p> <h3 id="team-interaction">Team interaction</h3> <p>Should be formalized and adversarial for growth. Interaction between engineer and analytic</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/team_protocol.excalidraw.png" alt="team.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Interaction should be objective and implicit</em></td> </tr> </tbody> </table> <p>Will discuss</p> <h3 id="big-csv">Big csv</h3> <p>Suppose pur pipeline succeeds in business application and comes time for scaling. Hence input starts to come in greater amount, which can not be handled with same resources.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/examples/big_csv.excalidraw.png" alt="bit_csv.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Scaling can be painful for DS</em></td> </tr> </tbody> </table> <p>Yet pandas dataframe isn‚Äôt best format for handling big data, as it‚Äôs not provide memory efficient storage. That can be optimized via challenging more and more tools like Polars, Ray and Spark. Yet business can not always wait for this</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/examples/analytic_hell.excalidraw.png" alt="bit_csv.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Scaling can be painful for Data Scientist</em></td> </tr> </tbody> </table> <p>Therefore, simple bash solution can handle problem more implicitly</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/examples/big_csv_solution.excalidraw.png" alt="big_csv_solution.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Branch and bound</em></td> </tr> </tbody> </table> <p>Engineer can solve problem in one line of code, which can ease first steps and proceeds with studying of goal framework. Re</p> <p>So that they can be gracefully proceeds with analytic codes.</p> <h3 id="critical-job-falls-and-analytic-want-to-revert-to-previous-version">Critical job falls and analytic want to revert to previous version</h3> <p>Developer should</p> <h2 id="code-implementation">Code implementation</h2> <p>Nitty details of implementation</p> <h3 id="s3-environment-organization">s3 environment organization</h3> <h2 id="setting-airflow-variables">Setting Airflow variables</h2> <p>Environments helps to test new ideas</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">airflow.models</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="n">Variable</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="sh">"</span><span class="s">db_url</span><span class="sh">"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="sh">""</span><span class="p">)</span>
<span class="n">Variable</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="sh">"</span><span class="s">my_json_var</span><span class="sh">"</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">num1</span><span class="sh">"</span><span class="p">:</span> <span class="mi">23</span><span class="p">,</span> <span class="sh">"</span><span class="s">num2</span><span class="sh">"</span><span class="p">:</span> <span class="mi">42</span><span class="p">},</span> <span class="n">serialize_json</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>Airflow operators are projected such way, that they change their behaviour with respect to current Airflow variables</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">airflow.models</span> <span class="kn">import</span> <span class="n">Variable</span>

</code></pre></div></div> <h3 id="template-from--yaml-structure">Template from yaml structure</h3> <p>Recall structure of pipeline yaml file</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">group</span><span class="pi">:</span> <span class="c1"># arbitrary group name</span>
    <span class="na">task</span><span class="pi">:</span> <span class="c1"># arbitrary task name</span>
      <span class="na">operator_type</span><span class="pi">:</span> <span class="s">pg_to_csv</span>
      <span class="na">columns</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s">ham</span>
        <span class="pi">-</span> <span class="s">bam</span>
</code></pre></div></div> <p>Resulted py file for airflow execution is done with jinja. You can read my code in following <a href="TODO">github</a></p> <p>Note that there is an alternative approach through <code class="language-plaintext highlighter-rouge">globals()</code> as it was done in <a href="https://github.com/rambler-digital-solutions/airflow-declarative">airflow-declarative</a>. Yet it less explicit as it doesn‚Äôt produce resulted python files.</p> <h3 id="node-based-programming">Node based programming</h3> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/airflow_automation/node_based/ui.png" alt="ui.ppg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Open source solution for class connection</em></td> </tr> </tbody> </table> <p>For ease of building new dags I introduced <a href="https://github.com/NMashalov/PyVisGraph">solution</a> based on <a href="https://github.com/jagenjo/litegraph.js/blob/master/build/litegraph.js">LiteGraph</a>.</p> <p>Solution was highly inspired by ComfyUI pipelining tool for Stable Diffusion.</p> <h2 id="summary">Summary</h2> <p>Thank for your reading. Hope that provide some intuition for your team. I compiled article insights for you</p> <ul> <li>Role model is convenient way of organizing team. Primarily, there are three basic roles: Data Scientist - business insights seekers, Engineer - support and critique, Developer - wires, monitors and rescales</li> <li>Yaml is convenient both for defining pipelines and configs</li> <li>decoupling of model and airflow repo can be done via s3</li> <li>partite s3 for models. That allows flexible versioning of data and models.</li> <li>cli is nice interface for interaction between engineer and data scientists</li> </ul>]]></content><author><name>Mashalov Nikita</name></author><summary type="html"><![CDATA[Article covers Airflow architecture for beginner enterprise ml team]]></summary></entry><entry><title type="html">Diffusion net notes</title><link href="https://nmashalov.github.io/blog/2024/diffusion_nets/" rel="alternate" type="text/html" title="Diffusion net notes"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/diffusion_nets</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/diffusion_nets/"><![CDATA[<h2 id="connection-to-stochastic-equations">Connection to stochastic equations</h2> <p>https://arxiv.org/abs/2108.01073</p> <h2 id="normal-distribution-information-geometry-approach">Normal distribution. Information geometry approach</h2> <p>It can be shown that riemanian metric of gaussian distribution is equal to: \(g = \frac{1}{\sigma^2}(d\mu^2+2d\sigma^2)\)</p> <p>That speculations is very important due to fact it‚Äôs curvature defines hyperbolic space.</p> <p>Hyperbolic space is naturally hierarchical</p> <h2 id="energy-based-methods">Energy-based methods</h2> <h2 id="ar">Ar</h2> <h2 id="physics-way-of-thinking-of-langevin-dynamics">Physics way of thinking of Langevin dynamics</h2> <p>Recall, Langevin gradient descent is brought by</p> \[x_{t+1} = x_t + \eta\] <p>Diffusion process are stochastic in local, but not one global scale. You can rule diffusion by simple temperature difference.</p> <p>But why add noise?</p> <p>A smarter way for representation is to ask why exactly gaussian noise?</p> <h2 id="central-limit-theorem">Central limit theorem</h2> <p>It‚Äôs well known fact:</p> <p>But why really that happens behind fuss of formulas? What is actual speed of convergence? And what‚Äôs more important what is so special about normal distribution?</p> <p>I‚Äôll provide you with intuition for answering this questions.</p> <h2 id="fokker-plank-equation">Fokker-Plank equation</h2> <p>https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation</p> \[\frac{\partial}{\partial t} p(x,t) = - \frac{\partial}{\partial x}[\mu(x,t)p(x,t)] + \partial{}{}\] <h2 id="diffusion-maps">Diffusion maps</h2> <p>Is approach for dimension reduction similar as PCA and t-SNE. You can read <a href="https://en.wikipedia.org/wiki/Diffusion_map">more</a></p> <h2 id="connection-to-optimal-transport">Connection to optimal transport</h2> <p>Yandex research paper</p> <p>Two steps:</p> <ol> <li>Transforming ODE to probability flow ODE</li> </ol> \[dx= -[x+\nabla_x \log p_t(x)]dt\] <ol> <li>Encoder map For a given distribution ¬µ0 and a timestep t, let us denote the flow generated by this vector field as E¬µ0 (t, ¬∑). I.e., a point x ‚àº ¬µ0 is mapped to E¬µ0 (t, x) when transported along the vector field for a time t. The ‚Äòfinal‚Äô encoding map is obtained when t ‚Üí ‚àû, i.e,</li> </ol> \[E_{\mu_0}(x) = \lim_{t \rightarrow \infty} E_{\mu_0}(t,x)\] <p>Note that $E_{\mu_0}$ implicitly depends on all the intermediate densities ¬µt obtained from the diffusion process (or the Fokker-Planck equation).</p> <p>The authors of <a href="https://arxiv.org/abs/2108.01073">Meng et al.</a> (2021) proposed to view diffusion models as a discretization of certain stochastic differential equations. SDEs generalize standard ordinary differential equations (ODEs) by injecting random noise into dynamics. Specifically, the diffusion process specified by Equation (1) is a discretization of the following SDE:</p> \[dx = -\frac{1}{2} \beta(t) xdt + \sqrt{\beta(t)} d\omega\] <p>r. It can be shown that the trajectory {¬µt}‚àû t=0, obtained by solving the Fokker-Planck equation</p> <h2 id="useful-resources">Useful resources</h2> <p>Blogs:</p> <ol> <li>Markov chains https://bjlkeng.io/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/</li> </ol> <p>Videos:</p> <ol> <li>https://www.youtube.com/watch?v=hbIfrLefwzw</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[Connection to stochastic equations]]></summary></entry><entry><title type="html">Flink SQL</title><link href="https://nmashalov.github.io/blog/2024/flink-SQL/" rel="alternate" type="text/html" title="Flink SQL"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/flink-SQL</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/flink-SQL/"><![CDATA[<d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="##Streaming architecture"> Streaming architecture </a></div> <div><a href="##tools"> Tools </a></div> <div><a href="##team"> Team </a></div> <div><a href="##code implementation">Code implementation</a></div> </nav> </d-contents> <p>Apache Flink is powerful streaming tool</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/flink/logo.excalidraw.png" alt="logo.png"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Fl</em></td> </tr> </tbody> </table> <p>In this article we will discuss step by step how to build architecture and then useful Flink concepts, which may seem unfamiliar may come at start.</p> <h2 id="streaming-architecture">Streaming architecture</h2> <p>Streaming application also known as near real time (NRT) are . They are widely used in credit scoring, geoanalytics and mobile.</p> <p>Current popular solutions are</p> <p>In this article I share my heuristics for building streaming application. I‚Äôll touch upon:</p> <ul> <li>ways to aggregate</li> </ul> <p>Assumptions:</p> <ul> <li>we are provided with enough of kafka</li> </ul> <p>Such assumptions helps us to:</p> <p>We get triggers of all cats</p> <h2 id="onion-architecture">Onion architecture</h2> <p>I‚Äôll give a quick overview over architecture</p> <table> <thead> <tr> <th>Layer</th> <th>Credo</th> <th>Principles</th> <th>Tech realisation</th> </tr> </thead> <tbody> <tr> <td>Feature extraction layer</td> <td>Extract as much as possible</td> <td>¬†</td> <td>¬†</td> </tr> </tbody> </table> <p>Teach realisation:</p> <ul> <li>feature extraction <ul> <li>every side streaming source will have it own kafka topic</li> <li>that topic should be filter only by your domain</li> <li>yet we don‚Äôt enrich it yet with our domain info</li> </ul> </li> <li>feature level <ul> <li>we merge all semantics group in one</li> <li>model scheme should have one datamodel</li> </ul> </li> <li>enrichment layer <ul> <li>we enrich</li> </ul> </li> <li>strategy layer <ul> <li>only nessary info for side developer</li> <li>all strategies are merged to one output topic</li> </ul> </li> </ul> <h2 id="architecture-judgement">Architecture judgement</h2> <p>Arhitecture brings useful decomposition.</p> <h2 id="feature-level">Feature level</h2> <p>On feature level we are interested on aggregating in planar format.</p> <p>Suppose we have nested structure</p> <h2 id="aggregation-level">Aggregation level</h2> <p>There are two ways to aggregate info with common schema or without. I‚Äôll share pros and cons of both approach.</p> <p>Common schema is beneficial for side developer. As he can. Also common schema allows to use AVRO for effective.</p> <p>Yet standardization can bring serious obstacles:</p> <ul> <li>fields with common</li> </ul> <p>First</p> <h2 id="flink-sql-syntax">Flink SQL syntax</h2> <p>They have awesome documentation</p> <p>Yet some reasonable features requires ad-hoc. I‚Äôll share you with some of my favorite.</p> <h2 id="understanding-time-in-flink">Understanding time in Flink</h2> <ul> <li>processed time</li> <li>event time</li> </ul> <h3 id="processed-time">Processed time</h3> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">proc_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">()</span>
</code></pre></div></div> <h3 id="event-time">Event time</h3> <p>As kafka is queue events are read sequentially. If we use event time we require</p> <p>When events doesn‚Äôt follow shedule they are called</p> <p>For mitigating late events you can use watermark</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">event_ts</span> <span class="nb">timestamp</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
<span class="n">WATERMARK</span> <span class="k">FOR</span> <span class="n">events_ts</span> <span class="k">AS</span> <span class="n">event_ts</span> <span class="o">-</span> <span class="n">INTERVAL</span> <span class="s1">'1'</span> <span class="k">MINUTE</span>
</code></pre></div></div> <p>With such definition we‚Äôll wait for late events for one minute.</p> <p>In brief watermark say operators that events before mark were already processed.</p> <h3 id="example">Example</h3> <p>Suppose we send our dataset of three events happend every minute</p> <table> <thead> <tr> <th>id</th> <th>ts</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>2023-01-12 10:30:00.000</td> </tr> <tr> <td>1</td> <td>2023-01-12 10:31:00.000</td> </tr> <tr> <td>1</td> <td>2023-01-12 10:32:00.000</td> </tr> </tbody> </table> <p>Using proctime</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="k">source</span><span class="p">(</span>
    <span class="n">id</span><span class="p">,</span>
    <span class="n">ts</span><span class="p">,</span>
    <span class="n">proc_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">()</span>
<span class="p">)</span>
<span class="k">FROM</span> <span class="n">source_table</span><span class="p">;</span>

<span class="k">SELECT</span> <span class="n">id</span> 
<span class="k">FROM</span> <span class="k">TABLE</span><span class="p">(</span><span class="n">TUMBLE</span><span class="p">(</span><span class="k">TABLE</span> <span class="k">source</span><span class="p">,</span> <span class="k">DESCRIPTOR</span><span class="p">(</span><span class="n">pc</span><span class="p">),</span> <span class="n">interval</span> <span class="s1">'1'</span> <span class="k">minute</span><span class="p">));</span>
</code></pre></div></div> <p>If we‚Äôll process it through using <code class="language-plaintext highlighter-rouge">processed_time</code> we‚Äôll get 3. Yet with use of</p> <h2 id="field-unpacking">Field unpacking</h2> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div> <h2 id="work-with-array">Work with array</h2> <h2 id="difficult-calculations">Difficult calculations.</h2> <p>Calculations are better perfomed sequentialy</p> <p>Haversine formula is used for calculating distance between two points defined by latitude and longitude.</p> <p>This formula is especially in geo-streaming applications.</p> <p>Exact formula is given by:</p> \[2 r \arcsin\left(\sqrt{\sin^2(\frac{\phi_1-\phi_2}{2}) + \cos \phi_1 \cos \phi_2 \sin^2 (\frac{\lambda_2-\lambda_1}{2})}\right)\] <p>It‚Äôs really difficult to</p> <p>I advise you to use chaining for facilitation of your work.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">power</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">locationLng1</span><span class="o">-</span><span class="n">locationLng2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span><span class="mi">360</span><span class="p">.,</span><span class="mi">2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">dlng</span><span class="p">,</span>
<span class="n">power</span><span class="p">(</span><span class="n">sin</span><span class="p">(</span><span class="n">locationLat1</span><span class="o">-</span><span class="n">locationLat2</span><span class="p">)</span><span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span><span class="mi">360</span><span class="p">.,</span><span class="mi">2</span><span class="p">)</span> <span class="k">AS</span> <span class="n">dlat</span><span class="p">,</span>
<span class="n">cos</span><span class="p">(</span><span class="n">locationLat1</span> <span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span> <span class="mi">180</span><span class="p">.)</span> <span class="k">AS</span> <span class="n">cos_loc1</span><span class="p">,</span>
<span class="n">cos</span><span class="p">(</span><span class="n">locationLat2</span> <span class="o">*</span> <span class="mi">3</span><span class="p">.</span><span class="mi">14</span><span class="o">/</span> <span class="mi">180</span><span class="p">.)</span> <span class="k">AS</span> <span class="n">cos_loc2</span><span class="p">,</span>
</code></pre></div></div> <p>I multiply by <code class="language-plaintext highlighter-rouge">3.14/180.</code> to convert gradus for radians. Earth radius üåé is approximately 6371 km. So final distance will be</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">2</span><span class="o">*</span><span class="mi">6371</span><span class="o">*</span><span class="n">asin</span><span class="p">(</span><span class="n">sqrt</span><span class="p">(</span><span class="n">dlat</span><span class="o">+</span><span class="n">cos_loc1</span><span class="o">*</span><span class="n">cos_loc2</span><span class="o">*</span><span class="n">dlng</span><span class="p">))</span>
</code></pre></div></div> <h2 id="use-of-cassandra">Use of Cassandra</h2> <p>Flink provides</p> <p>Not all tables can b</p> <p><a href="https://cassandra.apache.org/_/index.html"></a></p> <h2 id="deduplication">Deduplication</h2> <p>Deduplication is essential in cases when you have a lot of events but you don‚Äôt want to overload.</p> <p>First I‚Äôll provide my approach and</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="n">id</span><span class="p">,</span>
    <span class="n">FIRST_VALUE</span><span class="p">(</span><span class="n">os</span><span class="p">)</span> <span class="k">AS</span> <span class="n">os</span>  
<span class="k">FROM</span> <span class="k">TABLE</span><span class="p">(</span>
    <span class="n">TUBMLE</span><span class="p">(</span>
        <span class="k">TABLE</span> <span class="n">mob_events</span><span class="p">,</span>
        <span class="k">DESCRIPTOR</span><span class="p">(</span><span class="n">proc_time</span><span class="p">),</span>
        <span class="n">INTERVAL</span> <span class="s1">'20'</span> <span class="k">SECOND</span>
    <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span> <span class="mi">1</span>
</code></pre></div></div> <p>Alternative</p> <p>SELECT id, FIRST_VALUE(os) AS os<br/> FROM TABLE( TUBMLE( TABLE mob_events, DESCRIPTOR(proc_time), INTERVAL ‚Äò20‚Äô SECOND ) ) ) GROUP BY 1</p> <p>This script</p> <p>First of all you need to know about time in Flink There are three types:</p> <ul> <li><strong>Processing time</strong>:</li> <li><strong>Event time</strong>‚Äù:</li> <li><strong>Ingestion time</strong>: time when event was <em>ingested</em> to operator</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="p">(</span>
    <span class="p">...</span>
    <span class="n">proc_time</span> <span class="k">AS</span> <span class="n">PROCTIME</span><span class="p">(),</span> 
    <span class="n">row_time</span> <span class="k">AS</span> <span class="k">LOCALTIMESTAMP</span> <span class="c1">-- normal timestamp(3)</span>
<span class="p">)</span> 
</code></pre></div></div> <p>That</p> <p>Also you need to know more about time windows in <a href="https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/operators/windows/">Flink</a></p> <h2 id="time-transformation">Time transformation</h2> <p>There a lot of formats of representing of time</p> <ul> <li>UNIX: in milliseconds or seconds from</li> <li>TIMESTAMP:</li> </ul> <p>Flink also specefies difference between timestamp.</p> <ul> <li>TIMESTAMP</li> <li>TIMESTAMP(3) - seconds</li> <li>TIMESTAMP(6) - miliseconds Probable cavets also can be timezones.</li> </ul> <p>For some cases it‚Äôs beneficial to convert them to each other</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">kafka_source</span><span class="p">(</span>
    <span class="c1">-- first you declare field</span>
    <span class="n">eventUnixTime</span> <span class="nb">BIGINT</span><span class="p">,</span>
    <span class="c1">-- then you transform it</span>
    <span class="c1">-- UNIXTIME work with seconds not ms</span>
    <span class="n">eventTimeStamp</span> <span class="k">AS</span> <span class="n">TO_TIMESTAMP</span><span class="p">(</span><span class="n">FROM_UNIXTIME</span><span class="p">(</span><span class="n">eventTimestamp</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">))</span>
<span class="p">)</span>
</code></pre></div></div> <p>You can cast time like <code class="language-plaintext highlighter-rouge">03-00-00</code> to <code class="language-plaintext highlighter-rouge">TIME</code> via simple:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- now it's TIME format</span>
<span class="k">CAST</span><span class="p">(</span><span class="n">time_zone_tm</span> <span class="k">AS</span> <span class="nb">TIME</span><span class="p">)</span> <span class="k">AS</span> <span class="n">time_zone_tm</span>
</code></pre></div></div> <p>Let‚Äôs some up with working case of selecting events from 9 to 20 o‚Äôclock with correction of timezone <code class="language-plaintext highlighter-rouge">time_zone_tm</code></p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- I'll write in where </span>
<span class="k">WHERE</span> <span class="n">TIMESTAMPDIFF</span><span class="p">(</span><span class="k">MINUTE</span><span class="p">)</span>
</code></pre></div></div> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">-- counts minutes from 0:00:00 to current time  </span>
<span class="n">TIMESTAMPDIFF</span><span class="p">(</span><span class="k">MINUTE</span><span class="p">,</span> <span class="k">CAST</span><span class="p">(</span><span class="k">CURRENT_DATE</span> <span class="k">as</span> <span class="n">timestmap</span><span class="p">),</span> <span class="n">LocalTimestmap</span> <span class="p">)</span>
</code></pre></div></div> <p>EXTRACT(HOUR FROM time_zone_tm) * 60 + 7 * 60 + 30 EXTRACT(MINUTE FROM time_zone_tm) + 19 * 60 +15</p> <h2 id="escaping-fields">Escaping fields</h2> <p>FlinkSQL allows to escape field with backticks like that</p> <pre><code class="language-SQL">CREATE TABLE kafka_source {
    id STRING,
    -- event STRING, can throw a mistake :( 
    `event` STRING 
}
</code></pre> <p>It can be a leverage in situation with overloaded words like <code class="language-plaintext highlighter-rouge">group</code> or <code class="language-plaintext highlighter-rouge">event</code></p> <h2 id="json-unpacking">JSON unpacking</h2> <p>Sometimes data in json is provided in encrypted format.</p> <pre><code class="language-JSON">{
    "time_info": 170123456,
    "Data": "asesdasd"
}
</code></pre> <p>First of all you nee</p> <p>Just use</p> <p>JSON_VALUE</p> <p>Flink has documentation, yet it‚Äôs syntaxis can look unfamiliar. Actually it‚Äôs just a way to navigate through hierarchical structures.</p> <p>I‚Äôll guide you through.</p> <ul> <li><code class="language-plaintext highlighter-rouge">$</code> - mean <code class="language-plaintext highlighter-rouge">self</code> in Python ot <code class="language-plaintext highlighter-rouge">this</code> in JavaScript sense. It</li> <li>[<code class="language-plaintext highlighter-rouge">a</code>] - helps to select field in map</li> <li>[0] - helps to select element in list. Recall that list is ordered structure.</li> </ul> <p>Unfortunatelly you can‚Äôt cast extracted field to your desire type inline like that</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>JSON_VALUE('DataJson')

</code></pre></div></div> <p>Sometimes</p> <p>Suppose our message has</p> <p>Yet a lot of</p> <h2 id="join-types">Join types</h2> <p>Joins can mess order of events!</p> <ul> <li> <p>regular join Can bring OOM errors</p> </li> <li> <p>interval join Flink automatically removes events</p> </li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT id

FROM source1 AS t1
JOIN source2 AS t2 ON
    s1.id = s2.id AND
    s1.ts BETWEEN t2.ts - INTERVAL '5' minute AND 
        t2.ts + INTERVAL '5' minute
</code></pre></div></div> <ul> <li>temporal joins Allows to work with time versioned</li> </ul> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SELECT  
FROM events AS t1
LEFT JOIN temporal_table FOR SYSTEM_TIME AS OF t1.event_time AS t2 ON
    t1.id = t2.id
</code></pre></div></div> <p>That join automatically choses maximum time before event.</p> <ul> <li>temporal join</li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[Flink SQL is a component of Apache Flink that enables users to perform SQL queries on streaming and batch data. It provides a familiar SQL interface for processing data streams and tables, making it easier for developers and data engineers to work with real-time and historical data in Flink applications.]]></summary></entry><entry><title type="html">Practical applications of optimal transport</title><link href="https://nmashalov.github.io/blog/2024/optimal_transport/" rel="alternate" type="text/html" title="Practical applications of optimal transport"/><published>2024-01-10T00:00:00+00:00</published><updated>2024-01-10T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/optimal_transport</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/optimal_transport/"><![CDATA[<h2 id="introduction">Introduction</h2> <p>Optimal transport is useful beyond classical problems of logistic and resource management. That method is somehow universal. I describe from my personal experience in NLP.</p> <p>Optimal transport is useful tool for data scientist. I‚Äôll bring case from my personal practice to prove.</p> <h2 id="business-case-matching-scripts">Business case. Matching scripts</h2> <p>Suppose we have call-center, where junior operators read scripts and more proficient colleagues speak freestyle. We want to match phrases from scripts to new original variations of freestylers.</p> <p>Modern neural nets models BERT provides us with convenient of vector representation of sentences.</p> <p>We actually have two distributions of sentences. First is for script sentences, second for</p> <p>You can read more about embeddings <a href="https://www.turing.com/kb/guide-on-word-embeddings-in-nlp">here</a>.</p> <p>In normal practice we use cosine similarity</p> \[\text{similarity} = \cos(\text{emb}_1,\text{emb}_2)\] <p>All we need is to bring optimal connection.</p> <h2 id="about-optimality">About optimality</h2> <p>Optimality is actually one of the way of thinking and defining objects.</p> <p>What‚Äôs more importantly you can relax</p> <h2 id="entropy-regularized-optimal-transport">Entropy regularized optimal transport</h2> \[\int_{x \in \Pi(\mu,\nu)}\] <h2 id="population-dynamics">Population dynamics</h2> <p>JKO flows:</p> <p>JKO flows also were studied by Petr Mokrov et.al <a href="https://arxiv.org/abs/2106.00736">Large-Scale Wasserstein Gradient Flows</a>.</p> <p>I met <a href="https://www.youtube.com/watch?v=XODDkScHIVc">Optimal Transport Modeling of Population Dynamics: Applications in Single-Cell by Charlotte Bunne</a> and their excelent ariticle</p> <p>Approach was elaborated in article https://arxiv.org/abs/2210.06662</p> <h2 id="fluid-approach">Fluid approach</h2> <p>It will be instructive to consider another formulation of the optimal transport, originating in spirit from the fluid dynamics (Benamou &amp; Brenier, 2000; Villani, 2003). Assume that at t = 0 we are given a set of ‚Äòparticles‚Äô from the density œÅ0 which move in such a way that at t = 1 their state is described by the density œÅ1. Moreover, these particles move in such that they perform the least amount of work. Formally, they minimize the following action:</p> \[A= \int_{0}^{1} \left(\sum_{x} |\dot{x}(t)|^2\right)dt\] <p>In continuous limit obtaining:</p> \[\inf_{\rho,v} \left\{\int_{0}^1 \int \rho_t(x) |v_t(x)|^2 dxdt; \frac{\partial \rho_t}{\partial t} + \nabla \dot (\rho_t v_t) =0\right\}\] <p>where the infimum is taken over all time-dependent probability densities</p> <h2 id="resources">Resources</h2> <p>Computational Optimal Transport by Marco Cuturi https://arxiv.org/pdf/1803.00567.pdf</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Optimal transport, also known as Monge-Kantorovich transport or Wasserstein distance, is a mathematical framework that deals with the optimal way to transport mass from one configuration to another, minimizing the cost of the transportation. This field has gained significant attention across various disciplines due to its theoretical richness and a wide range of practical applications.]]></summary></entry><entry><title type="html">Neural Painting</title><link href="https://nmashalov.github.io/blog/2024/neural_painting/" rel="alternate" type="text/html" title="Neural Painting"/><published>2024-01-09T00:00:00+00:00</published><updated>2024-01-09T00:00:00+00:00</updated><id>https://nmashalov.github.io/blog/2024/neural_painting</id><content type="html" xml:base="https://nmashalov.github.io/blog/2024/neural_painting/"><![CDATA[<p>Neural Painting is research direction which is particular helpful for ease of artist and animators. It was primarly used in anime production.</p> <p>Basicaly there are two types of neural painting:</p> <ul> <li>inpainting. type of image restoration method that leverages neural networks to fill in missing or damaged parts of images.</li> <li>stroke-based aim to enhance the creative process by providing intelligent suggestions or guidance to artists, allowing them to generate strokes more efficiently and with greater artistic control.</li> </ul> <h2 id="style2paints">Style2Paints</h2> <p>Popular tool for colorisation of line art https://lllyasviel.github.io/Style2PaintsResearch/</p> <p>Despite v4 version used classical methods, v5 now use stable diffusion for colorization.</p> <h2 id="tracking">Tracking</h2> <p>https://ttwong12.github.io/papers/toontrack/toontrack.html</p> <p>https://potrace.sourceforge.net/</p> <p><img src="https://potrace.sourceforge.net/img/head-orig3.png" alt="Cheetah!"/></p> <h2 id="sceletionization">Sceletionization</h2> <p>Is a technique from morphology to extraction low dimensional curve embedded in observed space.</p> <p>https://lllyasviel.github.io/DanbooRegion/paper/paper.pdf</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tricks</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="n">skimage.morphology</span> <span class="kn">import</span> <span class="n">skeletonize</span><span class="p">,</span> <span class="n">dilation</span>

<span class="k">def</span> <span class="nf">get_skeleton</span><span class="p">(</span><span class="n">region_map</span><span class="p">):</span>
    <span class="n">Xp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">region_map</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="sh">'</span><span class="s">symmetric</span><span class="sh">'</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">Yp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">pad</span><span class="p">(</span><span class="n">region_map</span><span class="p">,</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="sh">'</span><span class="s">symmetric</span><span class="sh">'</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">Xp</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">Xp</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">Yp</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">Yp</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:])</span> <span class="o">**</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.5</span>
    <span class="n">edge</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">region_map</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">edge</span><span class="p">[</span><span class="n">X</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[</span><span class="n">Y</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">edge</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">skeleton</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="nf">dilation</span><span class="p">(</span><span class="n">edge</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">)</span>
    <span class="n">skeleton</span> <span class="o">=</span> <span class="nf">skeletonize</span><span class="p">(</span><span class="n">skeleton</span><span class="p">)</span>
    <span class="n">skeleton</span> <span class="o">=</span> <span class="p">(</span><span class="n">skeleton</span> <span class="o">*</span> <span class="mf">255.0</span><span class="p">).</span><span class="nf">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="n">field</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">edge</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="nf">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
    <span class="n">field</span><span class="p">[</span><span class="n">skeleton</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">255</span>
    <span class="n">field</span><span class="p">[</span><span class="n">edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="nb">filter</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="mf">5.0</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">field</span><span class="p">.</span><span class="n">shape</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">512</span><span class="p">):</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">filter2D</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">CV_32F</span><span class="p">,</span> <span class="nb">filter</span><span class="p">)</span>
        <span class="n">height</span><span class="p">[</span><span class="n">skeleton</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">255.0</span>
        <span class="n">height</span><span class="p">[</span><span class="n">edge</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">height</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span><span class="o">==</span><span class="sh">'</span><span class="s">__main__</span><span class="sh">'</span><span class="p">:</span>
    <span class="kn">import</span> <span class="n">sys</span>
    <span class="n">region_map</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">sys</span><span class="p">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">cv2</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="sh">'</span><span class="s">vis</span><span class="sh">'</span><span class="p">,</span> <span class="nf">get_skeleton</span><span class="p">(</span><span class="n">region_map</span><span class="p">))</span>
    <span class="n">cv2</span><span class="p">.</span><span class="nf">waitKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h2 id="datasets">Datasets</h2> <p>Main source of dataset is Danbooru provided by <a href="https://gwern.net/">Gwern</a>.,</p> <p>Dataset preparation:</p> <p>https://github.com/lllyasviel/DanbooRegion/tree/master?tab=readme-ov-file</p> <p>https://gwern.net/doc/ai/anime/danbooru/2023-kim.pdf https://lllyasviel.github.io/SplitFilling/</p> <h2 id="edgar-simo-serra">Edgar Simo-Serra</h2> <p>Collections of work on morphological coloring of pictures. https://esslab.jp/</p> <p>Start from scetch infilling</p> <ul> <li>Scetch Simplification</li> <li>Mastering Sketching https://arxiv.org/pdf/1703.08966.pdf</li> </ul> <p>Dataset</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/nerual_drawing/Simo-Serra/drawing.png" alt="drawing.jpg"/></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Sketch Simplification</em></td> </tr> </tbody> </table> <h2 id="notable-work">Notable work</h2> <p>https://github.com/moellenh/flatgan https://dl.acm.org/doi/10.1145/3581783.3613788</p> <p>https://github.com/houseofsecrets/SdPaint Skeletonize</p> <p>https://github.com/ermongroup/SDEdit</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Neural painting refers to a creative technique that uses neural networks, particularly generative models like deep neural networks (DNNs) or generative adversarial networks (GANs), to generate images or artwork based on input from users or predefined styles. This process involves training a neural network on a large dataset of images to learn the characteristics of different artistic styles or content. Users can then interactively guide the generation process by providing input, such as sketches, text descriptions, or reference images, to influence the output. Neural painting allows for the creation of diverse and aesthetically pleasing images, often blurring the lines between human and machine creativity.]]></summary></entry></feed>