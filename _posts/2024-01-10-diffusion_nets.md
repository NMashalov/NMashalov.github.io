---
layout: post
title: Diffusion net notes
---


## Normal distribution. Information geometry approach


It can be shown that riemanian metric of gaussian distribution is equal to:
$$
    g = \frac{1}{\sigma^2}(d\mu^2+2d\sigma^2)
$$

That speculations is very important due to fact it's curvature defines hyperbolic space.

Hyperbolic space is naturally hierarchical


## Energy-based methods

## Ar

## Physics way of thinking of Langevin dynamics

Recall, Langevin gradient descent is brought by 

$$
    x_{t+1} = x_t + \eta
$$

Diffusion process are stochastic in local, but not one global scale. You can rule diffusion by simple temperature difference. 



But why add noise?

A smarter way for representation is to ask why exactly gaussian noise? 

## Central limit theorem

It's well known fact:


But why really that happens behind fuss of formulas? What is actual speed of convergence? And what's more important what is so special about normal distribution? 

I'll provide you with intuition for answering this questions.


## Fokker-Plank equation

https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation

$$
    \frac{\partial}{\partial t} p(x,t) = - \frac{\partial}{\partial x}[\mu(x,t)p(x,t)] + \partial{}{}
$$


## Diffusion maps

Is approach for dimension reduction similar as PCA and t-SNE. You can read [more](https://en.wikipedia.org/wiki/Diffusion_map)


## Connection to optimal transport

Two steps:
1. Transforming ODE to probability flow ODE

$$
    dx= -[x+\nabla_x \log p_t(x)]dt
$$

2. Encoder map
For a given distribution µ0 and a timestep t,
let us denote the flow generated by this vector field as Eµ0
(t, ·). I.e., a point x ∼ µ0 is mapped to
Eµ0
(t, x) when transported along the vector field for a time t. The ‘final’ encoding map is obtained
when t → ∞, i.e,

$$
    E_{\mu_0}(x) = \lim_{t \rightarrow \infty} E_{\mu_0}(t,x)
$$

Note that $E_{\mu_0}$
implicitly depends on all the intermediate densities µt obtained from the diffusion
process (or the Fokker-Planck equation).

The authors of [Meng et al.](https://arxiv.org/abs/2108.01073) (2021) proposed to view diffusion models as a discretization of certain
stochastic differential equations. SDEs generalize standard ordinary differential equations (ODEs) by
injecting random noise into dynamics. Specifically, the diffusion process specified by Equation (1) is
a discretization of the following SDE:

$$
    dx = -\frac{1}{2} \beta(t) xdt + \sqrt{\beta(t)} d\omega
$$


r. It can be shown that the
trajectory {µt}∞
t=0, obtained by solving the Fokker-Planck equation

## Useful resources
Blogs:
1. Markov chains https://bjlkeng.io/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/
   
Videos:
1. https://www.youtube.com/watch?v=hbIfrLefwzw