<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Neuroscience | Nikita Mashalov</title> <meta name="author" content="Nikita Mashalov"> <meta name="description" content="Brief overview of advances in conjunction of Deep Learning and neuroscience"> <meta name="keywords" content="Mashalov Nikita, machine learning, artificial intelligence, AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%94%AD&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nmashalov.github.io/blog/2024/neuroscience/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?6185d15ea1982787ad7f435576553d64"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Neuroscience",
      "description": "Brief overview of advances in conjunction of Deep Learning and neuroscience",
      "published": "February 21, 2024",
      "authors": [
        {
          "author": "Mashalov Nikita",
          "authorURL": "",
          "affiliations": [
            {
              "name": "MIPT",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Nikita Mashalov</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Neuroscience</h1> <p>Brief overview of advances in conjunction of Deep Learning and neuroscience</p> </d-title><d-byline></d-byline><d-article> <p>Biological networks are much more than just scalar weights. It has activation time and phase different phases of work. Recent works have proved efficacy of neuro-informed approaches.</p> <h2 id="latent-representation">Latent representation</h2> <p>Represents world events in his own latent space. In easiest case it is just a representation of place</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/latent.excalidraw.png" alt="map.jpg"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center">**</td> </tr> </tbody> </table> <p>You can learn more about manifold in <a href="https://nmashalov.github.io/blog/2024/manifold/" rel="external nofollow noopener" target="_blank">blog</a>.</p> <p>Hypothesis of latent representation is well studied and summarized via biological perspective in excellent videos of Artem Kirsanov <a href="https://www.youtube.com/watch?v=QHj9uVmwA_0" rel="external nofollow noopener" target="_blank">Neural manifolds - The Geometry of Behaviour</a> and <a href="https://www.youtube.com/watch?v=9ujnZcaqf-4" rel="external nofollow noopener" target="_blank">Your brain is moving along the surface of the torus ðŸ¤¯</a>.</p> <p>Latent representation are unique among all people. Yet we are capable to share via <em>communication</em>, which have certain formats. Through perspective of machine learning that is called <a href="https://en.wikipedia.org/wiki/Sparse_dictionary_learning" rel="external nofollow noopener" target="_blank">Sparse coding</a>. That idea is very similar to basis in linear algebra.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/neuroscience/dictionary.excalidraw.png" alt="map.jpg"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Communication has lotâ€™s of forms</em></td> </tr> </tbody> </table> <p>From experience of communication we learn to correspond specific communication as certain combination of semantic recognition.</p> <h3 id="one-more-insight-motion-integrals">One more insight. Motion integrals</h3> <p>When you sit in a train, you donâ€™t check to , you <em>just remember it</em>.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/neuroscience/dictionary.excalidraw.png" alt="map.jpg"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Communication has lotâ€™s of forms</em></td> </tr> </tbody> </table> <p>From perspective of analytic mechanics it means that we coresponds to first integral. That means in your semantic space you can <em>decouple</em> preserving and changing.</p> <p>Moreover, we can say that through years we learn to do that with many things. We learn them an. That helps to concentrate on reall</p> <h2 id="ensembles">Ensembles</h2> <p>Combinatorial representation of system as possible collections of states</p> <p>Why we need lotâ€™s neuronms</p> <p>Symmetry can exhibit various dimensions. Describing a rotation transformation in n-dimensional space requires a minimum of n-1 parameters. If represented as a matrix, the parameter space expands by a factor of n. Within a grid, this transformation is learned as a distinctive structure, which may further augment its complexity.</p> <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/neuroscience/high_dim_symmetry.excalidraw.png" alt="pipeline.jpg"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Example of high dimensional symmetry that embedded in 2 dimensional picture</em></td> </tr> </tbody> </table> <p>Look at following picture. One of the symmetry that net might learn is that all cars, therefore they can be permuted without loss of sense.</p> \[P = \begin{pmatrix} 0 &amp; 0 &amp; \cdots &amp; 1 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 1 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; 0 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 1 &amp; \cdots &amp; 0 &amp; \cdots &amp; 0 \end{pmatrix}\] <p>For learning such symmetries we high dimensional matrix, hence more neurons</p> <h2 id="neural-coding">Neural coding</h2> <p>A way how brain transfer information.</p> <h2 id="liquid-networks">Liquid networks</h2> <p>Isâ€™s a conspect from <a href="https://www.youtube.com/watch?v=IlliqYiRhMU" rel="external nofollow noopener" target="_blank">Liquid Neural Networks</a></p> <p>Leaky-integrator model</p> \[\frac{d \mathbf{x}}{d t} = - \frac{\mathbf{x}(t)}{\tau} + \mathbf{S}(t)\] <p>Conductance-based synapce model</p> \[\mathbf{S}(t) = f(\mathbf{x}(t),\mathbf{I}(t),t, \theta)(A - \mathbf{x}(t))\] \[\frac{d \mathbf{x}}{d t } = - \left[ \frac{1}{\tau} + \underbrace{f(\mathbf{x}(t,\mathbf{I}(t),t,\theta)}_{\text{Liquid variable}}) \right] \mathbf{x}(t) + f(\mathbf{x}(t,\mathbf{I}(t),t,\theta)) A\] <table> <thead> <tr> <th style="text-align: center"><img src="/assets/img/posts/neuroscience/liquid_achieve.excalidraw.png" alt="lattice.png"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><em>Screenshot from presentation</em></td> </tr> </tbody> </table> <h3 id="new-hopfiled-networks">New Hopfiled networks</h3> <p>Recall that are two type of states</p> <p>Were introduced in Paper Dense Associative Memory for Pattern Recognition https://arxiv.org/abs/1606.01164</p> <p>Old pair-wise interaction</p> \[E = - \frac{1}{2} \sum_{i,j=1}^N \sigma_i T_{ij} \sigma_j\] <p>New non-linear</p> \[E = - \sum_{\mu =1}^K F(\xi_i^\mu \sigma_i)\] <p>Which comes in exponential increase in capacity of stored memories.</p> <p>With drawback of that we need to store all of them</p> <p>Increased capacity of recognised</p> <h3 id="reservoir-computing">Reservoir computing</h3> <p>Next generation reservoir computing https://www.nature.com/articles/s41467-021-25801-2</p> <p>Introduction to Next Generation Reservoir Computing https://www.youtube.com/watch?v=wbH4En-k5Gs</p> <h3 id="forward-forward">Forward-forward</h3> <p>Backpropagation and the brain https://www.nature.com/articles/s41583-020-0277-3</p> <p>Checkout notebook</p> <p>https://github.com/EscVM/EscVM_YT/blob/master/Notebooks/2%20-%20PT1.X%20DeepAI-Quickie/pt_1_forward_forward_alg.ipynb</p> <h2 id="read-more">Read more</h2> <p>Lecun Latent World <a href="https://openreview.net/pdf?id=BZ5a1r-kVsf" rel="external nofollow noopener" target="_blank"></a>. Here is effective paraphrase of article. For effective work we need to concentrate, despite changing. For that we have instrisic representation of world. It helps to find something that preserves in time, so we need ti</p> <p>HAMUX https://github.com/bhoov/hamux</p> <p>Free energy Karl Friston https://www.fil.ion.ucl.ac.uk/~karl/A%20free%20energy%20principle%20for%20the%20brain.pdf</p> <p>Relating transformers to models and neural representations of the hippocampal formation https://arxiv.org/abs/2112.04035</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2024 Nikita Mashalov. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>